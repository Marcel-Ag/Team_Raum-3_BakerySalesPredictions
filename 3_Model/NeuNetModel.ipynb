{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.typing as npt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import os\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv(\"../0_DataPreparation/processed_data_imputed.csv\")\n",
    "\n",
    "# Handle missing values in 'Bewoelkung'\n",
    "data['Bewoelkung'] = data['Bewoelkung'].fillna(data['Bewoelkung'].mean())\n",
    "\n",
    "# Filter out rows with Umsatz = 0\n",
    "data = data[data['Umsatz'] != 0]\n",
    "\n",
    "# Ensure 'Datum' is in datetime format\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], errors='coerce')\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = [\n",
    "    'KiWo', 'Is_Weekend', 'Temperature_Category',\n",
    "    'Wind_Status', 'Rain_Status',\n",
    "    'Cloud_Status','Is_Ferien','Sommerferien_Flag', 'Christmas_Sales','Warengruppe_1', 'Warengruppe_2',\n",
    "    'Warengruppe_3', 'Warengruppe_4', 'Warengruppe_5', 'Warengruppe_6'\n",
    "]\n",
    "\n",
    "print(\"Final feature columns used in training:\", feature_columns)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "training_start_date = '2013-07-01'\n",
    "training_end_date = '2017-07-31'\n",
    "validation_start_date = '2017-08-01'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "train_data = data[(data['Datum'] >= training_start_date) & (data['Datum'] <= training_end_date)]\n",
    "val_data = data[(data['Datum'] >= validation_start_date) & (data['Datum'] <= validation_end_date)]\n",
    "\n",
    "X_train = train_data[feature_columns].to_numpy()\n",
    "y_train = train_data['Umsatz'].to_numpy()\n",
    "X_val = val_data[feature_columns].to_numpy()\n",
    "y_val = val_data['Umsatz'].to_numpy()\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),  # Input layer\n",
    "    Dense(32, activation='relu'),                             # Hidden layer\n",
    "    Dense(16, activation='relu'),                             # Hidden layer\n",
    "    Dense(1, activation='linear')                             # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred = model.predict(X_val).flatten()\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "mape = mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "validation_cost = mse * len(y_val) / 2\n",
    "\n",
    "print(f\"Best RÂ²: {r2:.4f}\")\n",
    "print(f\"Validation cost: {validation_cost:.4e}\")\n",
    "print(f\"Mean Squared Error (MSE) on validation set: {mse:.4e}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Extract and display model parameters (weights from the first layer)\n",
    "weights, biases = model.layers[0].get_weights()\n",
    "\n",
    "print(\"\\nFinal Model Parameters:\")\n",
    "for i, feature in enumerate(feature_columns):\n",
    "    print(f\"Feature: {feature}, Weight: {weights[i][0]:.4f}\")\n",
    "print(f\"Intercept (b): {biases[0]:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/3_Model/nn_model.h5\"\n",
    "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to: {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Paths to the files\n",
    "processed_data_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/processed_data_imputed.csv\"\n",
    "sample_submission_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/sample_submission.csv\"\n",
    "final_submission_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/3_Model/final_submission.csv\"\n",
    "model_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/3_Model/nn_model.h5\"\n",
    "\n",
    "# Load the processed data and sample submission\n",
    "processed_data = pd.read_csv(processed_data_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "\n",
    "# Dynamically rebuild feature columns\n",
    "feature_columns = [\n",
    "    'KiWo', 'Is_Weekend', 'Temperature_Category',\n",
    "    'Wind_Status', 'Rain_Status',\n",
    "    'Cloud_Status','Is_Ferien','Sommerferien_Flag', 'Christmas_Sales','Warengruppe_1', 'Warengruppe_2',\n",
    "    'Warengruppe_3', 'Warengruppe_4', 'Warengruppe_5', 'Warengruppe_6'\n",
    "]\n",
    "\n",
    "# Extract features for prediction\n",
    "X_new = processed_data[feature_columns].apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float64)\n",
    "\n",
    "# Load the trained neural network model\n",
    "model = load_model(\n",
    "    model_path,\n",
    "    custom_objects={'mse': MeanSquaredError()}  # Ensure compatibility with saved model\n",
    ")\n",
    "\n",
    "# Normalize features using the same scaler used during training\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(X_new)  # Use saved scaler if available\n",
    "\n",
    "# Add the predicted values (y_pred) to the processed data\n",
    "processed_data['Predicted_Umsatz'] = y_pred\n",
    "\n",
    "# Merge predictions with sample submission to ensure matching structure\n",
    "final_submission = sample_submission.merge(processed_data[['id', 'Predicted_Umsatz']], on='id', how='left')\n",
    "\n",
    "# Replace the existing 'Umsatz' column in sample_submission with 'Predicted_Umsatz'\n",
    "final_submission['Umsatz'] = final_submission['Predicted_Umsatz']\n",
    "\n",
    "# Drop the 'Predicted_Umsatz' column after replacement\n",
    "final_submission.drop(columns=['Predicted_Umsatz'], inplace=True)\n",
    "\n",
    "# Replace null values in the Umsatz column with 0\n",
    "final_submission['Umsatz'] = final_submission['Umsatz'].fillna(0)\n",
    "\n",
    "# Round the 'Umsatz' values to 2 decimal places\n",
    "final_submission['Umsatz'] = final_submission['Umsatz'].round(2)\n",
    "\n",
    "# Keep only 'id' and 'Umsatz' columns\n",
    "final_submission = final_submission[['id', 'Umsatz']]\n",
    "\n",
    "# Save the final submission file\n",
    "os.makedirs(os.path.dirname(final_submission_path), exist_ok=True)\n",
    "final_submission.to_csv(final_submission_path, index=False)\n",
    "\n",
    "print(f\"Final submission saved to: {final_submission_path}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
