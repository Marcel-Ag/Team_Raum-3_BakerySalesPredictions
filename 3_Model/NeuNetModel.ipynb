{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature columns used in training: ['KiWo', 'Is_Weekend', 'Temperature_Category', 'Windgeschwindigkeit_Beaufort', 'Rain_Status', 'Bewoelkung', 'Weihnachten_Sommer', 'Christmas_Sales', 'Warengruppe_1', 'Warengruppe_2', 'Warengruppe_3', 'Warengruppe_4', 'Warengruppe_5', 'Warengruppe_6']\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55323.1445 - mae: 183.4389 - val_loss: 4574.8740 - val_mae: 48.7232\n",
      "Epoch 2/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5151.3970 - mae: 49.4468 - val_loss: 4539.6943 - val_mae: 47.6936\n",
      "Epoch 3/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4376.6318 - mae: 45.4948 - val_loss: 3986.3386 - val_mae: 43.6881\n",
      "Epoch 4/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4359.7959 - mae: 43.3858 - val_loss: 3644.2112 - val_mae: 41.0730\n",
      "Epoch 5/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4225.4165 - mae: 42.3559 - val_loss: 3938.4727 - val_mae: 43.1126\n",
      "Epoch 6/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4028.9775 - mae: 40.4922 - val_loss: 3468.4099 - val_mae: 39.5423\n",
      "Epoch 7/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5069.3037 - mae: 40.9499 - val_loss: 3985.0042 - val_mae: 43.1202\n",
      "Epoch 8/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3995.8882 - mae: 40.9357 - val_loss: 3576.2737 - val_mae: 40.4716\n",
      "Epoch 9/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4451.5347 - mae: 40.3623 - val_loss: 3245.1082 - val_mae: 37.5024\n",
      "Epoch 10/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4440.2603 - mae: 40.1567 - val_loss: 3310.6030 - val_mae: 38.0395\n",
      "Epoch 11/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4234.0386 - mae: 39.2409 - val_loss: 3595.2104 - val_mae: 40.1145\n",
      "Epoch 12/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3820.1682 - mae: 38.9807 - val_loss: 3769.0007 - val_mae: 41.2635\n",
      "Epoch 13/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4931.3438 - mae: 39.9370 - val_loss: 3351.2698 - val_mae: 38.2675\n",
      "Epoch 14/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4084.4404 - mae: 39.1398 - val_loss: 3655.5891 - val_mae: 40.3666\n",
      "Epoch 15/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4067.5916 - mae: 38.8142 - val_loss: 3397.9175 - val_mae: 38.4575\n",
      "Epoch 16/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5296.4238 - mae: 39.5626 - val_loss: 3750.3057 - val_mae: 40.9618\n",
      "Epoch 17/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4143.8657 - mae: 38.5067 - val_loss: 3689.2185 - val_mae: 40.5841\n",
      "Epoch 18/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4279.2964 - mae: 39.5992 - val_loss: 3548.5498 - val_mae: 39.7554\n",
      "Epoch 19/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3719.0171 - mae: 39.1353 - val_loss: 3446.7910 - val_mae: 38.8905\n",
      "Epoch 20/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4296.0049 - mae: 39.7911 - val_loss: 3100.2112 - val_mae: 36.2914\n",
      "Epoch 21/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3715.1775 - mae: 37.8509 - val_loss: 3209.7456 - val_mae: 37.2965\n",
      "Epoch 22/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3870.1565 - mae: 38.7666 - val_loss: 3741.5454 - val_mae: 40.3418\n",
      "Epoch 23/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4051.5786 - mae: 38.3401 - val_loss: 3003.6982 - val_mae: 35.3742\n",
      "Epoch 24/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3680.2122 - mae: 37.9417 - val_loss: 3824.3901 - val_mae: 41.8639\n",
      "Epoch 25/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3876.4988 - mae: 38.4837 - val_loss: 3411.0747 - val_mae: 38.6637\n",
      "Epoch 26/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4069.6548 - mae: 38.6413 - val_loss: 3580.5601 - val_mae: 40.1119\n",
      "Epoch 27/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3708.8823 - mae: 38.3669 - val_loss: 3861.2876 - val_mae: 42.1073\n",
      "Epoch 28/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3506.8542 - mae: 37.9807 - val_loss: 3786.7722 - val_mae: 41.5769\n",
      "Epoch 29/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4123.0718 - mae: 37.7463 - val_loss: 3167.9912 - val_mae: 36.8568\n",
      "Epoch 30/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4534.0718 - mae: 38.5118 - val_loss: 3726.2434 - val_mae: 40.4567\n",
      "Epoch 31/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5256.7729 - mae: 39.2006 - val_loss: 3816.7080 - val_mae: 41.6918\n",
      "Epoch 32/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4001.5181 - mae: 38.6929 - val_loss: 3267.8938 - val_mae: 37.3601\n",
      "Epoch 33/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3530.6555 - mae: 37.3646 - val_loss: 3986.1235 - val_mae: 42.5525\n",
      "Epoch 34/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4700.7969 - mae: 38.6660 - val_loss: 3329.6060 - val_mae: 37.7212\n",
      "Epoch 35/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3970.4414 - mae: 38.0286 - val_loss: 3390.2490 - val_mae: 38.2166\n",
      "Epoch 36/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4190.3896 - mae: 38.6665 - val_loss: 3696.7539 - val_mae: 40.9788\n",
      "Epoch 37/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3641.7754 - mae: 38.3191 - val_loss: 3436.9956 - val_mae: 39.0081\n",
      "Epoch 38/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3515.1362 - mae: 38.1546 - val_loss: 3331.2173 - val_mae: 37.8813\n",
      "Epoch 39/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3448.7051 - mae: 37.9204 - val_loss: 3587.0593 - val_mae: 39.9732\n",
      "Epoch 40/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4753.4561 - mae: 38.5186 - val_loss: 3301.8440 - val_mae: 37.7717\n",
      "Epoch 41/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4620.6733 - mae: 38.6485 - val_loss: 3469.5747 - val_mae: 38.8278\n",
      "Epoch 42/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4344.1362 - mae: 37.5316 - val_loss: 3466.4180 - val_mae: 39.3959\n",
      "Epoch 43/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3676.7375 - mae: 37.2687 - val_loss: 3334.5959 - val_mae: 38.1502\n",
      "Epoch 44/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4120.0762 - mae: 37.8487 - val_loss: 3175.9641 - val_mae: 36.8562\n",
      "Epoch 45/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3274.1328 - mae: 37.2174 - val_loss: 3408.3027 - val_mae: 38.4220\n",
      "Epoch 46/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4091.8792 - mae: 38.4416 - val_loss: 3254.1731 - val_mae: 37.3123\n",
      "Epoch 47/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4742.0688 - mae: 37.8528 - val_loss: 3464.3896 - val_mae: 39.5173\n",
      "Epoch 48/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4189.9844 - mae: 37.8090 - val_loss: 3496.8542 - val_mae: 39.1451\n",
      "Epoch 49/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3590.8645 - mae: 37.7749 - val_loss: 3991.4197 - val_mae: 42.4906\n",
      "Epoch 50/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4232.8320 - mae: 37.4145 - val_loss: 3288.5862 - val_mae: 38.0487\n",
      "Epoch 51/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3236.5295 - mae: 37.0835 - val_loss: 3615.5520 - val_mae: 39.9241\n",
      "Epoch 52/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3328.9648 - mae: 37.3016 - val_loss: 3681.2634 - val_mae: 40.7104\n",
      "Epoch 53/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3600.2417 - mae: 37.0977 - val_loss: 3513.2354 - val_mae: 39.6031\n",
      "Epoch 54/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4043.0200 - mae: 37.1317 - val_loss: 3607.5066 - val_mae: 39.9684\n",
      "Epoch 55/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4207.7500 - mae: 37.9798 - val_loss: 3400.4417 - val_mae: 38.2129\n",
      "Epoch 56/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4832.8779 - mae: 38.6042 - val_loss: 3473.9756 - val_mae: 38.7731\n",
      "Epoch 57/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4765.6284 - mae: 37.5911 - val_loss: 3246.7944 - val_mae: 37.4043\n",
      "Epoch 58/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3689.7349 - mae: 37.5869 - val_loss: 3715.4414 - val_mae: 40.6641\n",
      "Epoch 59/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3652.9941 - mae: 36.8931 - val_loss: 3507.4060 - val_mae: 39.2044\n",
      "Epoch 60/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3243.5007 - mae: 36.7365 - val_loss: 3481.5596 - val_mae: 38.9279\n",
      "Epoch 61/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3473.6553 - mae: 37.2046 - val_loss: 3476.6572 - val_mae: 39.0192\n",
      "Epoch 62/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3627.2642 - mae: 37.3698 - val_loss: 3224.3320 - val_mae: 37.0678\n",
      "Epoch 63/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3659.8406 - mae: 36.9216 - val_loss: 3298.4824 - val_mae: 37.7218\n",
      "Epoch 64/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3770.4568 - mae: 37.4411 - val_loss: 3228.7446 - val_mae: 36.8485\n",
      "Epoch 65/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4172.3164 - mae: 38.5811 - val_loss: 3929.9302 - val_mae: 42.7053\n",
      "Epoch 66/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3457.2036 - mae: 37.1837 - val_loss: 3361.4587 - val_mae: 37.8233\n",
      "Epoch 67/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2988.6299 - mae: 36.1898 - val_loss: 3322.1501 - val_mae: 37.5870\n",
      "Epoch 68/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3632.3362 - mae: 36.8700 - val_loss: 3734.2581 - val_mae: 40.2357\n",
      "Epoch 69/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4206.9126 - mae: 37.6118 - val_loss: 3744.0991 - val_mae: 40.7661\n",
      "Epoch 70/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4025.0491 - mae: 38.5098 - val_loss: 3354.2664 - val_mae: 38.0942\n",
      "Epoch 71/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3923.9175 - mae: 37.5923 - val_loss: 3441.3562 - val_mae: 38.7284\n",
      "Epoch 72/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4346.9316 - mae: 38.2258 - val_loss: 2989.5847 - val_mae: 35.0792\n",
      "Epoch 73/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3528.7815 - mae: 36.9481 - val_loss: 3368.5317 - val_mae: 37.7697\n",
      "Epoch 74/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4332.3677 - mae: 37.6720 - val_loss: 3334.4333 - val_mae: 37.6823\n",
      "Epoch 75/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3468.4363 - mae: 36.6729 - val_loss: 3257.8159 - val_mae: 36.9528\n",
      "Epoch 76/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3952.9263 - mae: 37.5964 - val_loss: 3585.8276 - val_mae: 39.7967\n",
      "Epoch 77/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3801.7502 - mae: 37.2644 - val_loss: 3617.3420 - val_mae: 40.0083\n",
      "Epoch 78/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4418.7349 - mae: 39.0295 - val_loss: 3356.1309 - val_mae: 38.2091\n",
      "Epoch 79/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4025.5964 - mae: 38.0919 - val_loss: 3154.6938 - val_mae: 36.1850\n",
      "Epoch 80/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3268.9399 - mae: 37.0818 - val_loss: 3309.2358 - val_mae: 37.2968\n",
      "Epoch 81/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4228.8301 - mae: 37.6045 - val_loss: 3380.3325 - val_mae: 38.0263\n",
      "Epoch 82/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4473.9565 - mae: 38.0199 - val_loss: 3246.3596 - val_mae: 37.3204\n",
      "Epoch 83/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3640.0684 - mae: 36.7387 - val_loss: 3584.3804 - val_mae: 39.6884\n",
      "Epoch 84/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4395.6147 - mae: 37.8494 - val_loss: 3307.4578 - val_mae: 37.3914\n",
      "Epoch 85/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3610.7659 - mae: 37.5191 - val_loss: 3476.6282 - val_mae: 39.0115\n",
      "Epoch 86/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3572.6213 - mae: 37.3678 - val_loss: 3630.5752 - val_mae: 39.9476\n",
      "Epoch 87/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3980.3130 - mae: 37.7496 - val_loss: 3331.1926 - val_mae: 37.8235\n",
      "Epoch 88/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2808.1204 - mae: 35.5398 - val_loss: 3740.8140 - val_mae: 41.0908\n",
      "Epoch 89/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3922.6074 - mae: 38.0848 - val_loss: 3659.4944 - val_mae: 40.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3995.0339 - mae: 37.5114 - val_loss: 3334.8679 - val_mae: 37.6280\n",
      "Epoch 91/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3958.8064 - mae: 38.1247 - val_loss: 3559.5947 - val_mae: 39.4652\n",
      "Epoch 92/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5496.4102 - mae: 38.4773 - val_loss: 3184.0842 - val_mae: 36.6401\n",
      "Epoch 93/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4141.0186 - mae: 37.3304 - val_loss: 3236.8516 - val_mae: 36.9799\n",
      "Epoch 94/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3525.7903 - mae: 37.3077 - val_loss: 3605.7881 - val_mae: 39.5242\n",
      "Epoch 95/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3516.1311 - mae: 37.2860 - val_loss: 3704.2388 - val_mae: 40.9289\n",
      "Epoch 96/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3654.9746 - mae: 37.5848 - val_loss: 3478.5352 - val_mae: 38.8717\n",
      "Epoch 97/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3417.5093 - mae: 36.5954 - val_loss: 3474.4368 - val_mae: 39.0584\n",
      "Epoch 98/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4444.1694 - mae: 37.9948 - val_loss: 3730.9397 - val_mae: 40.4458\n",
      "Epoch 99/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3972.0344 - mae: 37.3795 - val_loss: 3377.8503 - val_mae: 37.6232\n",
      "Epoch 100/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3589.4082 - mae: 37.4513 - val_loss: 3929.5361 - val_mae: 41.6463\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R²: 0.7683\n",
      "Validation cost: 3.5975e+06\n",
      "Mean Squared Error (MSE) on validation set: 3.9295e+03\n",
      "Mean Absolute Percentage Error (MAPE): 0.25%\n",
      "\n",
      "Final Model Parameters:\n",
      "Feature: KiWo, Weight: -0.2620\n",
      "Feature: Is_Weekend, Weight: 0.0055\n",
      "Feature: Temperature_Category, Weight: 0.2335\n",
      "Feature: Windgeschwindigkeit_Beaufort, Weight: -0.0141\n",
      "Feature: Rain_Status, Weight: -0.1268\n",
      "Feature: Bewoelkung, Weight: -0.1479\n",
      "Feature: Weihnachten_Sommer, Weight: 0.2235\n",
      "Feature: Christmas_Sales, Weight: -0.4975\n",
      "Feature: Warengruppe_1, Weight: -0.5043\n",
      "Feature: Warengruppe_2, Weight: -0.0438\n",
      "Feature: Warengruppe_3, Weight: -0.6228\n",
      "Feature: Warengruppe_4, Weight: -0.5788\n",
      "Feature: Warengruppe_5, Weight: 0.2832\n",
      "Feature: Warengruppe_6, Weight: -0.1340\n",
      "Intercept (b): -0.4896\n",
      "Model saved to: /workspaces/Team_Raum-3_BakerySalesPredictions/3_Model/nn_model.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import os\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv(\"../0_DataPreparation/processed_data.csv\")\n",
    "\n",
    "# Handle missing values in 'Bewoelkung'\n",
    "data['Bewoelkung'] = data['Bewoelkung'].fillna(data['Bewoelkung'].mean())\n",
    "\n",
    "# Filter out rows with Umsatz = 0\n",
    "data = data[data['Umsatz'] != 0]\n",
    "\n",
    "# Ensure 'Datum' is in datetime format\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], errors='coerce')\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = [\n",
    "    'KiWo', 'Is_Weekend', 'Temperature_Category',\n",
    "    'Windgeschwindigkeit_Beaufort', 'Rain_Status',\n",
    "    'Bewoelkung','Weihnachten_Sommer', 'Christmas_Sales','Warengruppe_1', 'Warengruppe_2',\n",
    "    'Warengruppe_3', 'Warengruppe_4', 'Warengruppe_5', 'Warengruppe_6'\n",
    "]\n",
    "\n",
    "print(\"Final feature columns used in training:\", feature_columns)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "training_start_date = '2013-07-01'\n",
    "training_end_date = '2017-07-31'\n",
    "validation_start_date = '2017-08-01'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "train_data = data[(data['Datum'] >= training_start_date) & (data['Datum'] <= training_end_date)]\n",
    "val_data = data[(data['Datum'] >= validation_start_date) & (data['Datum'] <= validation_end_date)]\n",
    "\n",
    "X_train = train_data[feature_columns].to_numpy()\n",
    "y_train = train_data['Umsatz'].to_numpy()\n",
    "X_val = val_data[feature_columns].to_numpy()\n",
    "y_val = val_data['Umsatz'].to_numpy()\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),  # Input layer\n",
    "    Dense(32, activation='relu'),                             # Hidden layer\n",
    "    Dense(16, activation='relu'),                             # Hidden layer\n",
    "    Dense(1, activation='linear')                             # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred = model.predict(X_val).flatten()\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "mape = mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "validation_cost = mse * len(y_val) / 2\n",
    "\n",
    "print(f\"Best R²: {r2:.4f}\")\n",
    "print(f\"Validation cost: {validation_cost:.4e}\")\n",
    "print(f\"Mean Squared Error (MSE) on validation set: {mse:.4e}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Extract and display model parameters (weights from the first layer)\n",
    "weights, biases = model.layers[0].get_weights()\n",
    "\n",
    "print(\"\\nFinal Model Parameters:\")\n",
    "for i, feature in enumerate(feature_columns):\n",
    "    print(f\"Feature: {feature}, Weight: {weights[i][0]:.4f}\")\n",
    "print(f\"Intercept (b): {biases[0]:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/3_Model/nn_model.h5\"\n",
    "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to: {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step\n",
      "Final submission saved to: /workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/final_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Paths to the files\n",
    "processed_data_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/processed_data.csv\"\n",
    "sample_submission_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/sample_submission.csv\"\n",
    "final_submission_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/final_submission.csv\"\n",
    "model_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/3_Model/nn_model.h5\"\n",
    "\n",
    "# Load the processed data and sample submission\n",
    "processed_data = pd.read_csv(processed_data_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "\n",
    "# Dynamically rebuild feature columns\n",
    "feature_columns = [\n",
    "    'KiWo', 'Is_Weekend', 'Temperature_Category',\n",
    "    'Windgeschwindigkeit_Beaufort', 'Rain_Status',\n",
    "    'Bewoelkung','Is_Ferien','Christmas_Sales','Warengruppe_1', 'Warengruppe_2',\n",
    "    'Warengruppe_3', 'Warengruppe_4', 'Warengruppe_5', 'Warengruppe_6'\n",
    "]\n",
    "\n",
    "# Extract features for prediction\n",
    "X_new = processed_data[feature_columns].apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float64)\n",
    "\n",
    "# Load the trained neural network model\n",
    "model = load_model(\n",
    "    model_path,\n",
    "    custom_objects={'mse': MeanSquaredError()}  # Ensure compatibility with saved model\n",
    ")\n",
    "\n",
    "# Normalize features using the same scaler used during training\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(X_new)  # Use saved scaler if available\n",
    "\n",
    "# Predict the output using the trained neural network\n",
    "y_pred = model.predict(X_new).flatten()\n",
    "\n",
    "# Add predictions to the processed data DataFrame\n",
    "processed_data['Predicted_Umsatz'] = y_pred\n",
    "\n",
    "# Merge predictions with sample submission to ensure matching structure\n",
    "final_submission = sample_submission[['id']].copy()\n",
    "final_submission = final_submission.merge(\n",
    "    processed_data[['ID', 'Predicted_Umsatz']],\n",
    "    how='left',\n",
    "    left_on='id',\n",
    "    right_on='ID'\n",
    ")\n",
    "\n",
    "# Drop the redundant 'ID' column and rename 'Predicted_Umsatz' to 'Umsatz'\n",
    "final_submission.drop(columns=['ID'], inplace=True)\n",
    "final_submission.rename(columns={'Predicted_Umsatz': 'Umsatz'}, inplace=True)\n",
    "\n",
    "# Replace null values in the Umsatz column with 0\n",
    "final_submission['Umsatz'] = final_submission['Umsatz'].fillna(0)\n",
    "\n",
    "# Save the final submission file\n",
    "os.makedirs(os.path.dirname(final_submission_path), exist_ok=True)\n",
    "final_submission.to_csv(final_submission_path, index=False)\n",
    "\n",
    "print(f\"Final submission saved to: {final_submission_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
