{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature columns used in training: ['KiWo', 'Is_Weekend', 'Temperature_Category', 'Windgeschwindigkeit_Beaufort', 'Rain_Status', 'Bewoelkung', 'Warengruppe_1', 'Warengruppe_2', 'Warengruppe_3', 'Warengruppe_4', 'Warengruppe_5', 'Warengruppe_6']\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 55622.0352 - mae: 183.0310 - val_loss: 4714.5835 - val_mae: 48.8034\n",
      "Epoch 2/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8802.7715 - mae: 61.6938 - val_loss: 4245.5225 - val_mae: 44.7217\n",
      "Epoch 3/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8096.1548 - mae: 61.8344 - val_loss: 4089.8923 - val_mae: 43.6064\n",
      "Epoch 4/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6756.6060 - mae: 55.4048 - val_loss: 4062.4939 - val_mae: 43.5316\n",
      "Epoch 5/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7811.0112 - mae: 55.5139 - val_loss: 3945.8137 - val_mae: 42.3747\n",
      "Epoch 6/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7117.5581 - mae: 54.1956 - val_loss: 4278.9995 - val_mae: 44.7119\n",
      "Epoch 7/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6856.9619 - mae: 55.6331 - val_loss: 3868.2595 - val_mae: 41.3405\n",
      "Epoch 8/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7566.9956 - mae: 57.2351 - val_loss: 4038.2654 - val_mae: 42.8815\n",
      "Epoch 9/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6807.4595 - mae: 55.8432 - val_loss: 3811.8323 - val_mae: 41.1107\n",
      "Epoch 10/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7480.8057 - mae: 55.4488 - val_loss: 3888.0884 - val_mae: 41.6563\n",
      "Epoch 11/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7278.5508 - mae: 55.4513 - val_loss: 3824.3152 - val_mae: 41.4762\n",
      "Epoch 12/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6456.6406 - mae: 54.4561 - val_loss: 3992.3203 - val_mae: 43.1680\n",
      "Epoch 13/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7894.9736 - mae: 55.7731 - val_loss: 3805.9377 - val_mae: 40.6713\n",
      "Epoch 14/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7008.0488 - mae: 54.8259 - val_loss: 4031.8752 - val_mae: 42.7701\n",
      "Epoch 15/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7052.4976 - mae: 54.5651 - val_loss: 3830.3831 - val_mae: 40.8094\n",
      "Epoch 16/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6661.1582 - mae: 54.8702 - val_loss: 3718.6428 - val_mae: 39.7525\n",
      "Epoch 17/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7018.9028 - mae: 54.3928 - val_loss: 3696.9514 - val_mae: 39.9465\n",
      "Epoch 18/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7389.6860 - mae: 54.4861 - val_loss: 3965.1104 - val_mae: 41.8806\n",
      "Epoch 19/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8191.6890 - mae: 55.2838 - val_loss: 3718.4534 - val_mae: 39.7824\n",
      "Epoch 20/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6545.3994 - mae: 53.3795 - val_loss: 3809.2610 - val_mae: 41.3778\n",
      "Epoch 21/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7708.3887 - mae: 55.0716 - val_loss: 3890.1226 - val_mae: 41.9202\n",
      "Epoch 22/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7590.2002 - mae: 54.8760 - val_loss: 3783.1636 - val_mae: 40.9954\n",
      "Epoch 23/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6848.9658 - mae: 52.8408 - val_loss: 3876.6968 - val_mae: 41.9742\n",
      "Epoch 24/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6692.6245 - mae: 53.8149 - val_loss: 4009.3293 - val_mae: 42.8273\n",
      "Epoch 25/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7751.5977 - mae: 54.3649 - val_loss: 3965.0581 - val_mae: 42.0552\n",
      "Epoch 26/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6564.4917 - mae: 52.3562 - val_loss: 3954.9995 - val_mae: 42.4849\n",
      "Epoch 27/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6685.1001 - mae: 54.5622 - val_loss: 3782.0466 - val_mae: 41.0439\n",
      "Epoch 28/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9738.7969 - mae: 56.2165 - val_loss: 3676.4890 - val_mae: 39.2899\n",
      "Epoch 29/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7815.8525 - mae: 53.9519 - val_loss: 3715.5715 - val_mae: 39.6625\n",
      "Epoch 30/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7820.2100 - mae: 53.9636 - val_loss: 3965.1567 - val_mae: 42.2066\n",
      "Epoch 31/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7712.9619 - mae: 53.8182 - val_loss: 3821.5396 - val_mae: 41.0931\n",
      "Epoch 32/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6443.1416 - mae: 52.4079 - val_loss: 3782.4280 - val_mae: 40.2994\n",
      "Epoch 33/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6395.0967 - mae: 51.7963 - val_loss: 3792.4761 - val_mae: 40.9231\n",
      "Epoch 34/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6789.8916 - mae: 52.0450 - val_loss: 3727.1433 - val_mae: 40.3013\n",
      "Epoch 35/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6861.8101 - mae: 52.9569 - val_loss: 3707.8220 - val_mae: 39.8163\n",
      "Epoch 36/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8093.0835 - mae: 54.3976 - val_loss: 3649.0596 - val_mae: 38.9099\n",
      "Epoch 37/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6350.8652 - mae: 51.9770 - val_loss: 3760.3967 - val_mae: 40.7510\n",
      "Epoch 38/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6764.7656 - mae: 52.3319 - val_loss: 3903.2612 - val_mae: 41.6531\n",
      "Epoch 39/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7875.5410 - mae: 53.8954 - val_loss: 3915.8989 - val_mae: 41.5858\n",
      "Epoch 40/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7117.3535 - mae: 53.6888 - val_loss: 3975.6514 - val_mae: 42.6579\n",
      "Epoch 41/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6422.3066 - mae: 52.1830 - val_loss: 3794.1799 - val_mae: 41.3088\n",
      "Epoch 42/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7213.7729 - mae: 53.3770 - val_loss: 3679.2310 - val_mae: 39.1581\n",
      "Epoch 43/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7354.7554 - mae: 52.3679 - val_loss: 3701.3208 - val_mae: 39.9207\n",
      "Epoch 44/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7326.4932 - mae: 54.3157 - val_loss: 3774.6724 - val_mae: 41.0145\n",
      "Epoch 45/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6117.0249 - mae: 50.6547 - val_loss: 3897.9658 - val_mae: 42.1678\n",
      "Epoch 46/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6538.7183 - mae: 52.4823 - val_loss: 3717.6904 - val_mae: 40.4646\n",
      "Epoch 47/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6008.2461 - mae: 52.3412 - val_loss: 3764.0510 - val_mae: 40.5684\n",
      "Epoch 48/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6790.4653 - mae: 51.8144 - val_loss: 4227.2295 - val_mae: 44.4453\n",
      "Epoch 49/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7392.0737 - mae: 54.0171 - val_loss: 3722.1335 - val_mae: 39.9717\n",
      "Epoch 50/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8090.9531 - mae: 54.6398 - val_loss: 3818.1816 - val_mae: 40.8965\n",
      "Epoch 51/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7593.1958 - mae: 53.5930 - val_loss: 3802.3696 - val_mae: 41.2555\n",
      "Epoch 52/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5832.7148 - mae: 50.6242 - val_loss: 3936.3120 - val_mae: 42.5427\n",
      "Epoch 53/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6798.9009 - mae: 52.0090 - val_loss: 4035.5129 - val_mae: 43.2849\n",
      "Epoch 54/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7460.7134 - mae: 52.6807 - val_loss: 3821.0503 - val_mae: 41.0602\n",
      "Epoch 55/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7013.6733 - mae: 53.9470 - val_loss: 3813.7778 - val_mae: 41.1066\n",
      "Epoch 56/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6898.5718 - mae: 51.4445 - val_loss: 3878.2947 - val_mae: 41.6726\n",
      "Epoch 57/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6723.9253 - mae: 51.7368 - val_loss: 3817.1436 - val_mae: 41.1715\n",
      "Epoch 58/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7298.6533 - mae: 53.7793 - val_loss: 3868.9497 - val_mae: 41.6751\n",
      "Epoch 59/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7521.4272 - mae: 52.9355 - val_loss: 3765.1489 - val_mae: 40.6618\n",
      "Epoch 60/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6430.8320 - mae: 51.1633 - val_loss: 3703.6794 - val_mae: 40.1827\n",
      "Epoch 61/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6290.9102 - mae: 52.0656 - val_loss: 3742.4624 - val_mae: 40.6009\n",
      "Epoch 62/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6349.3052 - mae: 52.3906 - val_loss: 3719.9917 - val_mae: 40.0683\n",
      "Epoch 63/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7200.3462 - mae: 52.3537 - val_loss: 3849.6450 - val_mae: 41.8427\n",
      "Epoch 64/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6683.9136 - mae: 52.7924 - val_loss: 3857.7056 - val_mae: 41.9526\n",
      "Epoch 65/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7123.8140 - mae: 52.5396 - val_loss: 4190.2866 - val_mae: 43.3196\n",
      "Epoch 66/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7059.1797 - mae: 52.7666 - val_loss: 3711.0630 - val_mae: 40.1760\n",
      "Epoch 67/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7135.1499 - mae: 52.1638 - val_loss: 3657.8120 - val_mae: 38.8199\n",
      "Epoch 68/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6309.7085 - mae: 50.9402 - val_loss: 3862.2168 - val_mae: 41.5966\n",
      "Epoch 69/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6598.8110 - mae: 52.0615 - val_loss: 3768.5344 - val_mae: 40.7800\n",
      "Epoch 70/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6370.6880 - mae: 51.7600 - val_loss: 3862.7791 - val_mae: 42.0272\n",
      "Epoch 71/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8667.5732 - mae: 53.6803 - val_loss: 3703.8962 - val_mae: 39.7584\n",
      "Epoch 72/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7454.3594 - mae: 52.8018 - val_loss: 3987.4902 - val_mae: 42.1010\n",
      "Epoch 73/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6731.2749 - mae: 52.4074 - val_loss: 3994.6035 - val_mae: 42.9475\n",
      "Epoch 74/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6338.2388 - mae: 51.5286 - val_loss: 3988.8589 - val_mae: 42.9242\n",
      "Epoch 75/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7918.5430 - mae: 52.5200 - val_loss: 3673.4194 - val_mae: 39.4541\n",
      "Epoch 76/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7018.9897 - mae: 53.7913 - val_loss: 3852.9866 - val_mae: 41.5435\n",
      "Epoch 77/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8126.4688 - mae: 53.3282 - val_loss: 3659.3420 - val_mae: 38.9626\n",
      "Epoch 78/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6434.8096 - mae: 51.4589 - val_loss: 3900.5132 - val_mae: 41.4237\n",
      "Epoch 79/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6847.7798 - mae: 52.6710 - val_loss: 3950.6135 - val_mae: 42.5467\n",
      "Epoch 80/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6936.8257 - mae: 52.4405 - val_loss: 3665.7529 - val_mae: 39.8647\n",
      "Epoch 81/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7378.0122 - mae: 51.2530 - val_loss: 3896.4961 - val_mae: 41.5192\n",
      "Epoch 82/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8464.3809 - mae: 52.3550 - val_loss: 3639.2031 - val_mae: 38.7338\n",
      "Epoch 83/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6393.2949 - mae: 51.8682 - val_loss: 3707.7859 - val_mae: 40.0818\n",
      "Epoch 84/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8001.9365 - mae: 53.3817 - val_loss: 3669.8101 - val_mae: 39.2965\n",
      "Epoch 85/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6948.7510 - mae: 51.5805 - val_loss: 3763.1260 - val_mae: 40.7406\n",
      "Epoch 86/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7344.5996 - mae: 52.3040 - val_loss: 3698.4226 - val_mae: 39.9556\n",
      "Epoch 87/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6390.1211 - mae: 52.1589 - val_loss: 3942.6106 - val_mae: 42.2031\n",
      "Epoch 88/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7168.0469 - mae: 52.9763 - val_loss: 3674.4858 - val_mae: 39.5212\n",
      "Epoch 89/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7131.6523 - mae: 51.7998 - val_loss: 3871.7446 - val_mae: 41.9302\n",
      "Epoch 90/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6308.5298 - mae: 51.0239 - val_loss: 3768.7534 - val_mae: 40.8147\n",
      "Epoch 91/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6625.2632 - mae: 52.2428 - val_loss: 3693.5432 - val_mae: 39.9500\n",
      "Epoch 92/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7003.8271 - mae: 51.7613 - val_loss: 3746.7581 - val_mae: 40.5217\n",
      "Epoch 93/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6483.3608 - mae: 51.6280 - val_loss: 3638.0728 - val_mae: 39.1287\n",
      "Epoch 94/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6923.3755 - mae: 51.4635 - val_loss: 3691.6282 - val_mae: 39.9587\n",
      "Epoch 95/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6001.3188 - mae: 50.9181 - val_loss: 3822.1035 - val_mae: 41.5139\n",
      "Epoch 96/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6141.9199 - mae: 50.1656 - val_loss: 4019.6035 - val_mae: 42.7809\n",
      "Epoch 97/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6464.6055 - mae: 50.6927 - val_loss: 4022.5166 - val_mae: 42.9605\n",
      "Epoch 98/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6992.3730 - mae: 53.2545 - val_loss: 3841.0317 - val_mae: 41.4236\n",
      "Epoch 99/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6625.6538 - mae: 52.5745 - val_loss: 3892.7786 - val_mae: 42.0122\n",
      "Epoch 100/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7979.6074 - mae: 52.7979 - val_loss: 3664.5178 - val_mae: 39.1469\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R²: 0.7840\n",
      "Validation cost: 3.3549e+06\n",
      "Mean Squared Error (MSE) on validation set: 3.6645e+03\n",
      "Mean Absolute Percentage Error (MAPE): 0.23%\n",
      "\n",
      "Final Model Parameters:\n",
      "Feature: KiWo, Weight: -0.0160\n",
      "Feature: Is_Weekend, Weight: 0.3013\n",
      "Feature: Temperature_Category, Weight: -0.0597\n",
      "Feature: Windgeschwindigkeit_Beaufort, Weight: 0.0058\n",
      "Feature: Rain_Status, Weight: -0.0833\n",
      "Feature: Bewoelkung, Weight: 0.0548\n",
      "Feature: Warengruppe_1, Weight: -0.3462\n",
      "Feature: Warengruppe_2, Weight: 0.3962\n",
      "Feature: Warengruppe_3, Weight: -0.2790\n",
      "Feature: Warengruppe_4, Weight: -0.1324\n",
      "Feature: Warengruppe_5, Weight: 0.2605\n",
      "Feature: Warengruppe_6, Weight: -0.1624\n",
      "Intercept (b): 0.1042\n",
      "Model saved to: /workspaces/Team_Raum-3_BakerySalesPredictions/3_Model/nn_model.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import os\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv(\"../0_DataPreparation/processed_data.csv\")\n",
    "\n",
    "# Handle missing values in 'Bewoelkung'\n",
    "data['Bewoelkung'] = data['Bewoelkung'].fillna(data['Bewoelkung'].mean())\n",
    "\n",
    "# Filter out rows with Umsatz = 0\n",
    "data = data[data['Umsatz'] != 0]\n",
    "\n",
    "# Ensure 'Datum' is in datetime format\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], errors='coerce')\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = [\n",
    "    'KiWo', 'Is_Weekend', 'Temperature_Category',\n",
    "    'Windgeschwindigkeit_Beaufort', 'Rain_Status',\n",
    "    'Bewoelkung', 'Warengruppe_1', 'Warengruppe_2', \n",
    "    'Warengruppe_3', 'Warengruppe_4', 'Warengruppe_5', 'Warengruppe_6'\n",
    "]\n",
    "\n",
    "print(\"Final feature columns used in training:\", feature_columns)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "training_start_date = '2013-07-01'\n",
    "training_end_date = '2017-07-31'\n",
    "validation_start_date = '2017-08-01'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "train_data = data[(data['Datum'] >= training_start_date) & (data['Datum'] <= training_end_date)]\n",
    "val_data = data[(data['Datum'] >= validation_start_date) & (data['Datum'] <= validation_end_date)]\n",
    "\n",
    "X_train = train_data[feature_columns].to_numpy()\n",
    "y_train = train_data['Umsatz'].to_numpy()\n",
    "X_val = val_data[feature_columns].to_numpy()\n",
    "y_val = val_data['Umsatz'].to_numpy()\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Build the neural network model with Dropout\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),  # Input layer\n",
    "    Dropout(0.2),                                             # Dropout layer\n",
    "    Dense(32, activation='relu'),                             # Hidden layer\n",
    "    Dropout(0.2),                                             # Dropout layer\n",
    "    Dense(16, activation='relu'),                             # Hidden layer\n",
    "    Dropout(0.2),                                             # Dropout layer\n",
    "    Dense(1, activation='linear')                             # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred = model.predict(X_val).flatten()\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "mape = mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "validation_cost = mse * len(y_val) / 2\n",
    "\n",
    "print(f\"Best R²: {r2:.4f}\")\n",
    "print(f\"Validation cost: {validation_cost:.4e}\")\n",
    "print(f\"Mean Squared Error (MSE) on validation set: {mse:.4e}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Extract and display model parameters (weights from the first layer)\n",
    "weights, biases = model.layers[0].get_weights()\n",
    "\n",
    "print(\"\\nFinal Model Parameters:\")\n",
    "for i, feature in enumerate(feature_columns):\n",
    "    print(f\"Feature: {feature}, Weight: {weights[i][0]:.4f}\")\n",
    "print(f\"Intercept (b): {biases[0]:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/3_Model/nn_model.h5\"\n",
    "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to: {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step\n",
      "Final submission saved to: /workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/final_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Paths to the files\n",
    "processed_data_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/processed_data.csv\"\n",
    "sample_submission_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/sample_submission.csv\"\n",
    "final_submission_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/final_submission.csv\"\n",
    "model_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/3_Model/nn_model.h5\"\n",
    "\n",
    "# Load the processed data and sample submission\n",
    "processed_data = pd.read_csv(processed_data_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "\n",
    "# Dynamically rebuild feature columns\n",
    "feature_columns = [\n",
    "    'KiWo', 'Is_Weekend', 'Temperature_Category',\n",
    "    'Windgeschwindigkeit_Beaufort', 'Rain_Status',\n",
    "    'Bewoelkung', 'Warengruppe_1', 'Warengruppe_2',\n",
    "    'Warengruppe_3', 'Warengruppe_4', 'Warengruppe_5', 'Warengruppe_6'\n",
    "]\n",
    "\n",
    "# Extract features for prediction\n",
    "X_new = processed_data[feature_columns].apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float64)\n",
    "\n",
    "# Load the trained neural network model\n",
    "model = load_model(\n",
    "    model_path,\n",
    "    custom_objects={'mse': MeanSquaredError()}  # Ensure compatibility with saved model\n",
    ")\n",
    "\n",
    "# Normalize features using the same scaler used during training\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(X_new)  # Use saved scaler if available\n",
    "\n",
    "# Predict the output using the trained neural network\n",
    "y_pred = model.predict(X_new).flatten()\n",
    "\n",
    "# Add predictions to the processed data DataFrame\n",
    "processed_data['Predicted_Umsatz'] = y_pred\n",
    "\n",
    "# Merge predictions with sample submission to ensure matching structure\n",
    "final_submission = sample_submission[['id']].copy()\n",
    "final_submission = final_submission.merge(\n",
    "    processed_data[['ID', 'Predicted_Umsatz']],\n",
    "    how='left',\n",
    "    left_on='id',\n",
    "    right_on='ID'\n",
    ")\n",
    "\n",
    "# Drop the redundant 'ID' column and rename 'Predicted_Umsatz' to 'Umsatz'\n",
    "final_submission.drop(columns=['ID'], inplace=True)\n",
    "final_submission.rename(columns={'Predicted_Umsatz': 'Umsatz'}, inplace=True)\n",
    "\n",
    "# Replace null values in the Umsatz column with 0\n",
    "final_submission['Umsatz'] = final_submission['Umsatz'].fillna(0)\n",
    "\n",
    "# Save the final submission file\n",
    "os.makedirs(os.path.dirname(final_submission_path), exist_ok=True)\n",
    "final_submission.to_csv(final_submission_path, index=False)\n",
    "\n",
    "print(f\"Final submission saved to: {final_submission_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
