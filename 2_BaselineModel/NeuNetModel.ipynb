{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature columns used in training: ['KiWo', 'Is_Weekend', 'Temperature_Category', 'Windgeschwindigkeit_Beaufort', 'Rain_Status', 'Bewoelkung', 'Warengruppe_1', 'Warengruppe_2', 'Warengruppe_3', 'Warengruppe_4', 'Warengruppe_5', 'Warengruppe_6']\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54687.0664 - mae: 177.9240 - val_loss: 5098.0957 - val_mae: 51.4958\n",
      "Epoch 2/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6419.6304 - mae: 50.8401 - val_loss: 4352.6973 - val_mae: 46.1682\n",
      "Epoch 3/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5805.7983 - mae: 47.1971 - val_loss: 4211.9028 - val_mae: 45.0847\n",
      "Epoch 4/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5675.0684 - mae: 45.9228 - val_loss: 4132.3115 - val_mae: 44.3860\n",
      "Epoch 5/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4773.6753 - mae: 43.8692 - val_loss: 4072.8196 - val_mae: 43.8885\n",
      "Epoch 6/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6656.8926 - mae: 44.9950 - val_loss: 4106.3027 - val_mae: 44.2025\n",
      "Epoch 7/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4752.0044 - mae: 43.3803 - val_loss: 4501.7734 - val_mae: 46.7729\n",
      "Epoch 8/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5102.5840 - mae: 44.3723 - val_loss: 3805.9058 - val_mae: 41.2947\n",
      "Epoch 9/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4693.9604 - mae: 43.1403 - val_loss: 4281.3286 - val_mae: 44.9252\n",
      "Epoch 10/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4827.3994 - mae: 43.3381 - val_loss: 4121.1362 - val_mae: 44.2701\n",
      "Epoch 11/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4187.6060 - mae: 42.4453 - val_loss: 3867.7871 - val_mae: 41.7701\n",
      "Epoch 12/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4147.0156 - mae: 42.1287 - val_loss: 4222.5020 - val_mae: 44.9820\n",
      "Epoch 13/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7040.1914 - mae: 44.9581 - val_loss: 4030.5991 - val_mae: 42.7776\n",
      "Epoch 14/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5814.3882 - mae: 43.2157 - val_loss: 4241.5000 - val_mae: 44.5883\n",
      "Epoch 15/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4502.1045 - mae: 42.8691 - val_loss: 4055.2715 - val_mae: 43.4372\n",
      "Epoch 16/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5108.5898 - mae: 43.2299 - val_loss: 3967.5671 - val_mae: 42.6678\n",
      "Epoch 17/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5883.3618 - mae: 43.4482 - val_loss: 4134.0376 - val_mae: 43.6048\n",
      "Epoch 18/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6583.9419 - mae: 44.5399 - val_loss: 4203.0303 - val_mae: 44.4979\n",
      "Epoch 19/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6314.8438 - mae: 43.7049 - val_loss: 4239.0488 - val_mae: 44.2785\n",
      "Epoch 20/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6357.8335 - mae: 44.1097 - val_loss: 4042.3838 - val_mae: 43.2267\n",
      "Epoch 21/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4560.1675 - mae: 41.7038 - val_loss: 3867.6177 - val_mae: 41.6625\n",
      "Epoch 22/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4776.4609 - mae: 43.1121 - val_loss: 4300.9087 - val_mae: 44.4583\n",
      "Epoch 23/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5621.7725 - mae: 43.0088 - val_loss: 4323.1992 - val_mae: 45.2319\n",
      "Epoch 24/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4859.8027 - mae: 42.6729 - val_loss: 4029.0032 - val_mae: 43.0111\n",
      "Epoch 25/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6275.2192 - mae: 43.2529 - val_loss: 4074.4421 - val_mae: 43.5829\n",
      "Epoch 26/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5721.6914 - mae: 43.4091 - val_loss: 4366.1895 - val_mae: 45.2471\n",
      "Epoch 27/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4258.6548 - mae: 42.5257 - val_loss: 4015.1516 - val_mae: 42.9113\n",
      "Epoch 28/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4158.1294 - mae: 41.7627 - val_loss: 3998.5906 - val_mae: 42.4959\n",
      "Epoch 29/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4660.7720 - mae: 43.2361 - val_loss: 4182.7378 - val_mae: 44.2803\n",
      "Epoch 30/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4114.2930 - mae: 42.3403 - val_loss: 3986.1194 - val_mae: 42.8191\n",
      "Epoch 31/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5374.4297 - mae: 42.9845 - val_loss: 4076.9531 - val_mae: 43.3678\n",
      "Epoch 32/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5305.3838 - mae: 42.7322 - val_loss: 4038.9546 - val_mae: 43.3958\n",
      "Epoch 33/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4395.5732 - mae: 41.3075 - val_loss: 4418.4033 - val_mae: 45.6295\n",
      "Epoch 34/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4625.3213 - mae: 42.3639 - val_loss: 3944.9836 - val_mae: 42.5262\n",
      "Epoch 35/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4183.0239 - mae: 42.5731 - val_loss: 4105.1885 - val_mae: 43.7807\n",
      "Epoch 36/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5420.1377 - mae: 42.6380 - val_loss: 4341.8052 - val_mae: 45.2783\n",
      "Epoch 37/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4755.3872 - mae: 42.1491 - val_loss: 4058.5229 - val_mae: 43.3788\n",
      "Epoch 38/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4858.1074 - mae: 42.3477 - val_loss: 3873.5269 - val_mae: 41.8553\n",
      "Epoch 39/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4777.9707 - mae: 42.0637 - val_loss: 4200.2803 - val_mae: 43.5245\n",
      "Epoch 40/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4889.5029 - mae: 41.8891 - val_loss: 3973.1104 - val_mae: 42.7571\n",
      "Epoch 41/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5055.3027 - mae: 42.0095 - val_loss: 4344.4736 - val_mae: 44.9138\n",
      "Epoch 42/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5035.6392 - mae: 43.0926 - val_loss: 4038.5051 - val_mae: 43.0355\n",
      "Epoch 43/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5617.4780 - mae: 42.9836 - val_loss: 4211.1074 - val_mae: 44.0238\n",
      "Epoch 44/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4011.2593 - mae: 41.3830 - val_loss: 3856.9683 - val_mae: 41.6989\n",
      "Epoch 45/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4152.7295 - mae: 41.5610 - val_loss: 3945.6868 - val_mae: 42.3509\n",
      "Epoch 46/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4018.4514 - mae: 42.1638 - val_loss: 4478.8833 - val_mae: 46.6992\n",
      "Epoch 47/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4330.2764 - mae: 42.7649 - val_loss: 3941.0522 - val_mae: 42.7574\n",
      "Epoch 48/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4412.5420 - mae: 41.6723 - val_loss: 4258.2363 - val_mae: 44.2511\n",
      "Epoch 49/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4800.7925 - mae: 42.9447 - val_loss: 3807.8894 - val_mae: 41.0691\n",
      "Epoch 50/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4557.9741 - mae: 42.5378 - val_loss: 4123.6191 - val_mae: 43.8907\n",
      "Epoch 51/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4909.1431 - mae: 41.8929 - val_loss: 4088.2371 - val_mae: 42.7503\n",
      "Epoch 52/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5369.7378 - mae: 42.2657 - val_loss: 3928.6033 - val_mae: 42.0741\n",
      "Epoch 53/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4294.3398 - mae: 41.5227 - val_loss: 3851.1213 - val_mae: 41.9829\n",
      "Epoch 54/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3837.8635 - mae: 41.5152 - val_loss: 4362.8330 - val_mae: 45.8948\n",
      "Epoch 55/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3879.1514 - mae: 41.7911 - val_loss: 3944.4265 - val_mae: 41.9889\n",
      "Epoch 56/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5339.0518 - mae: 42.7266 - val_loss: 3763.9807 - val_mae: 40.8090\n",
      "Epoch 57/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4893.5278 - mae: 42.0645 - val_loss: 4008.6218 - val_mae: 42.5983\n",
      "Epoch 58/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4795.7891 - mae: 42.3300 - val_loss: 3924.9546 - val_mae: 41.8094\n",
      "Epoch 59/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4801.9126 - mae: 42.6105 - val_loss: 4174.3496 - val_mae: 44.2082\n",
      "Epoch 60/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5456.1963 - mae: 41.5574 - val_loss: 3965.7920 - val_mae: 42.2397\n",
      "Epoch 61/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5461.0576 - mae: 42.7678 - val_loss: 3925.5378 - val_mae: 42.1670\n",
      "Epoch 62/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4782.5410 - mae: 41.5566 - val_loss: 4123.0269 - val_mae: 43.6624\n",
      "Epoch 63/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4684.2808 - mae: 41.7393 - val_loss: 4119.0474 - val_mae: 43.8264\n",
      "Epoch 64/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4966.5298 - mae: 42.6329 - val_loss: 4006.6362 - val_mae: 42.5126\n",
      "Epoch 65/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4259.6035 - mae: 40.7386 - val_loss: 3882.0498 - val_mae: 41.9729\n",
      "Epoch 66/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4780.7402 - mae: 41.7897 - val_loss: 4060.4194 - val_mae: 43.1319\n",
      "Epoch 67/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5163.2588 - mae: 42.6392 - val_loss: 4019.3660 - val_mae: 42.7683\n",
      "Epoch 68/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5299.6021 - mae: 42.7918 - val_loss: 4400.5889 - val_mae: 45.6277\n",
      "Epoch 69/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5557.9824 - mae: 42.4972 - val_loss: 3787.6431 - val_mae: 41.1274\n",
      "Epoch 70/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4829.6821 - mae: 42.4783 - val_loss: 3924.5225 - val_mae: 42.5799\n",
      "Epoch 71/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3888.3386 - mae: 41.1582 - val_loss: 3763.3425 - val_mae: 41.0005\n",
      "Epoch 72/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5795.8789 - mae: 43.0877 - val_loss: 4123.6577 - val_mae: 43.6323\n",
      "Epoch 73/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5946.9932 - mae: 42.7929 - val_loss: 3950.3840 - val_mae: 41.9240\n",
      "Epoch 74/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6289.2607 - mae: 43.1591 - val_loss: 4028.4600 - val_mae: 42.6795\n",
      "Epoch 75/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5336.7905 - mae: 41.9870 - val_loss: 3943.0767 - val_mae: 42.3141\n",
      "Epoch 76/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4425.6299 - mae: 42.0608 - val_loss: 3900.8157 - val_mae: 42.0508\n",
      "Epoch 77/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4916.5771 - mae: 42.3170 - val_loss: 4041.9087 - val_mae: 42.5178\n",
      "Epoch 78/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4479.7939 - mae: 41.0940 - val_loss: 4834.4946 - val_mae: 48.4458\n",
      "Epoch 79/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5279.8760 - mae: 42.5910 - val_loss: 3956.7539 - val_mae: 42.1386\n",
      "Epoch 80/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5869.2051 - mae: 42.0148 - val_loss: 3819.1770 - val_mae: 40.9099\n",
      "Epoch 81/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5035.9263 - mae: 41.8120 - val_loss: 3889.7749 - val_mae: 41.6777\n",
      "Epoch 82/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4798.3667 - mae: 41.5067 - val_loss: 4269.5356 - val_mae: 44.3865\n",
      "Epoch 83/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5162.4365 - mae: 42.0890 - val_loss: 4223.4067 - val_mae: 44.3291\n",
      "Epoch 84/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4708.5732 - mae: 41.1506 - val_loss: 3807.9131 - val_mae: 41.0206\n",
      "Epoch 85/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5023.7617 - mae: 43.0483 - val_loss: 4678.1230 - val_mae: 47.3737\n",
      "Epoch 86/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4967.3315 - mae: 41.8920 - val_loss: 3824.0735 - val_mae: 41.2090\n",
      "Epoch 87/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4932.4365 - mae: 41.4868 - val_loss: 3915.9028 - val_mae: 42.0081\n",
      "Epoch 88/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4494.5083 - mae: 42.0267 - val_loss: 4270.5840 - val_mae: 44.8003\n",
      "Epoch 89/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4173.1660 - mae: 41.8176 - val_loss: 4462.3315 - val_mae: 46.3298\n",
      "Epoch 90/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4240.8228 - mae: 41.8244 - val_loss: 3826.0608 - val_mae: 40.8225\n",
      "Epoch 91/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3980.8347 - mae: 41.1490 - val_loss: 4190.6055 - val_mae: 44.2348\n",
      "Epoch 92/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5143.9219 - mae: 41.5854 - val_loss: 3898.4541 - val_mae: 41.6577\n",
      "Epoch 93/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4011.4941 - mae: 40.3659 - val_loss: 4134.3735 - val_mae: 43.7448\n",
      "Epoch 94/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5347.1611 - mae: 43.0262 - val_loss: 3775.5212 - val_mae: 40.6044\n",
      "Epoch 95/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5490.8906 - mae: 42.1726 - val_loss: 3934.9998 - val_mae: 41.8077\n",
      "Epoch 96/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4201.0244 - mae: 41.3812 - val_loss: 3854.0986 - val_mae: 41.5102\n",
      "Epoch 97/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5284.9707 - mae: 42.7308 - val_loss: 3676.2561 - val_mae: 39.4850\n",
      "Epoch 98/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4108.8452 - mae: 41.6165 - val_loss: 3871.0339 - val_mae: 41.4194\n",
      "Epoch 99/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4429.8774 - mae: 40.9291 - val_loss: 4529.3677 - val_mae: 46.0485\n",
      "Epoch 100/100\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3942.5933 - mae: 41.8857 - val_loss: 3995.1296 - val_mae: 42.9899\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R²: 0.7645\n",
      "Validation cost: 3.6575e+06\n",
      "Mean Squared Error (MSE) on validation set: 3.9951e+03\n",
      "Mean Absolute Percentage Error (MAPE): 0.25%\n",
      "\n",
      "Final Model Parameters:\n",
      "Feature: KiWo, Weight: -0.2857\n",
      "Feature: Is_Weekend, Weight: -0.1081\n",
      "Feature: Temperature_Category, Weight: 0.7445\n",
      "Feature: Windgeschwindigkeit_Beaufort, Weight: 0.1595\n",
      "Feature: Rain_Status, Weight: 0.2718\n",
      "Feature: Bewoelkung, Weight: 0.4877\n",
      "Feature: Warengruppe_1, Weight: -0.5401\n",
      "Feature: Warengruppe_2, Weight: -0.0781\n",
      "Feature: Warengruppe_3, Weight: -0.3699\n",
      "Feature: Warengruppe_4, Weight: -0.1338\n",
      "Feature: Warengruppe_5, Weight: 0.3555\n",
      "Feature: Warengruppe_6, Weight: -0.3754\n",
      "Intercept (b): 0.1030\n",
      "Model saved to: /workspaces/Team_Raum-3_BakerySalesPredictions/3_Model/nn_model.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import os\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv(\"../0_DataPreparation/processed_data.csv\")\n",
    "\n",
    "# Handle missing values in 'Bewoelkung'\n",
    "data['Bewoelkung'] = data['Bewoelkung'].fillna(data['Bewoelkung'].mean())\n",
    "\n",
    "# Filter out rows with Umsatz = 0\n",
    "data = data[data['Umsatz'] != 0]\n",
    "\n",
    "# Ensure 'Datum' is in datetime format\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], errors='coerce')\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = [\n",
    "    'KiWo', 'Is_Weekend', 'Temperature_Category',\n",
    "    'Windgeschwindigkeit_Beaufort', 'Rain_Status',\n",
    "    'Bewoelkung', 'Warengruppe_1', 'Warengruppe_2', \n",
    "    'Warengruppe_3', 'Warengruppe_4', 'Warengruppe_5', 'Warengruppe_6'\n",
    "]\n",
    "\n",
    "print(\"Final feature columns used in training:\", feature_columns)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "training_start_date = '2013-07-01'\n",
    "training_end_date = '2017-07-31'\n",
    "validation_start_date = '2017-08-01'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "train_data = data[(data['Datum'] >= training_start_date) & (data['Datum'] <= training_end_date)]\n",
    "val_data = data[(data['Datum'] >= validation_start_date) & (data['Datum'] <= validation_end_date)]\n",
    "\n",
    "X_train = train_data[feature_columns].to_numpy()\n",
    "y_train = train_data['Umsatz'].to_numpy()\n",
    "X_val = val_data[feature_columns].to_numpy()\n",
    "y_val = val_data['Umsatz'].to_numpy()\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),  # Input layer\n",
    "    Dense(32, activation='relu'),                             # Hidden layer\n",
    "    Dense(16, activation='relu'),                             # Hidden layer\n",
    "    Dense(1, activation='linear')                             # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred = model.predict(X_val).flatten()\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "mape = mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "validation_cost = mse * len(y_val) / 2\n",
    "\n",
    "print(f\"Best R²: {r2:.4f}\")\n",
    "print(f\"Validation cost: {validation_cost:.4e}\")\n",
    "print(f\"Mean Squared Error (MSE) on validation set: {mse:.4e}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Extract and display model parameters (weights from the first layer)\n",
    "weights, biases = model.layers[0].get_weights()\n",
    "\n",
    "print(\"\\nFinal Model Parameters:\")\n",
    "for i, feature in enumerate(feature_columns):\n",
    "    print(f\"Feature: {feature}, Weight: {weights[i][0]:.4f}\")\n",
    "print(f\"Intercept (b): {biases[0]:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/3_Model/nn_model.h5\"\n",
    "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to: {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n",
      "Final submission saved to: /workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/final_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Paths to the files\n",
    "processed_data_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/processed_data.csv\"\n",
    "sample_submission_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/sample_submission.csv\"\n",
    "final_submission_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/final_submission.csv\"\n",
    "model_path = \"/workspaces/Team_Raum-3_BakerySalesPredictions/3_Model/nn_model.h5\"\n",
    "\n",
    "# Load the processed data and sample submission\n",
    "processed_data = pd.read_csv(processed_data_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "\n",
    "# Dynamically rebuild feature columns\n",
    "feature_columns = [\n",
    "    'KiWo', 'Is_Weekend', 'Temperature_Category',\n",
    "    'Windgeschwindigkeit_Beaufort', 'Rain_Status',\n",
    "    'Bewoelkung', 'Warengruppe_1', 'Warengruppe_2',\n",
    "    'Warengruppe_3', 'Warengruppe_4', 'Warengruppe_5', 'Warengruppe_6'\n",
    "]\n",
    "\n",
    "# Extract features for prediction\n",
    "X_new = processed_data[feature_columns].apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float64)\n",
    "\n",
    "# Load the trained neural network model\n",
    "model = load_model(\n",
    "    model_path,\n",
    "    custom_objects={'mse': MeanSquaredError()}  # Ensure compatibility with saved model\n",
    ")\n",
    "\n",
    "# Normalize features using the same scaler used during training\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(X_new)  # Use saved scaler if available\n",
    "\n",
    "# Predict the output using the trained neural network\n",
    "y_pred = model.predict(X_new).flatten()\n",
    "\n",
    "# Add predictions to the processed data DataFrame\n",
    "processed_data['Predicted_Umsatz'] = y_pred\n",
    "\n",
    "# Merge predictions with sample submission to ensure matching structure\n",
    "final_submission = sample_submission[['id']].copy()\n",
    "final_submission = final_submission.merge(\n",
    "    processed_data[['ID', 'Predicted_Umsatz']],\n",
    "    how='left',\n",
    "    left_on='id',\n",
    "    right_on='ID'\n",
    ")\n",
    "\n",
    "# Drop the redundant 'ID' column and rename 'Predicted_Umsatz' to 'Umsatz'\n",
    "final_submission.drop(columns=['ID'], inplace=True)\n",
    "final_submission.rename(columns={'Predicted_Umsatz': 'Umsatz'}, inplace=True)\n",
    "\n",
    "# Replace null values in the Umsatz column with 0\n",
    "final_submission['Umsatz'] = final_submission['Umsatz'].fillna(0)\n",
    "\n",
    "# Save the final submission file\n",
    "os.makedirs(os.path.dirname(final_submission_path), exist_ok=True)\n",
    "final_submission.to_csv(final_submission_path, index=False)\n",
    "\n",
    "print(f\"Final submission saved to: {final_submission_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
