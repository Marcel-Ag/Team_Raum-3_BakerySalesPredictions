{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the processed data and feature columns\n",
    "wetter_umsatzdaten_kiwo = pd.read_csv(\"../1_DatasetCharacteristics/processed_data.csv\")\n",
    "\n",
    "# Feature columns (excluding one-hot encoded Warengruppe columns)\n",
    "feature_columns = ['Bewoelkung', 'Temperatur', 'Windgeschwindigkeit', 'Wettercode', \n",
    "                   'KiWo', 'Is_Weekend', 'Temperature_Category', 'Windgeschwindigkeit_Beaufort']\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "training_start_date = '2013-07-01'\n",
    "training_end_date = '2017-07-31'\n",
    "validation_start_date = '2017-08-01'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "# Regularization functions remain the same\n",
    "def compute_cost_reg(X, y, w, b, lambda_):\n",
    "    m = X.shape[0]\n",
    "    cost = (1 / (2 * m)) * np.sum((np.dot(X, w) + b - y) ** 2)\n",
    "    reg_cost = (lambda_ / (2 * m)) * np.sum(w ** 2)\n",
    "    return cost + reg_cost\n",
    "\n",
    "def gradient_descent_reg(X, y, w_in, b_in, alpha, num_iters, lambda_):\n",
    "    w = w_in\n",
    "    b = b_in\n",
    "    for _ in range(num_iters):\n",
    "        dj_dw = (1 / len(X)) * np.dot((np.dot(X, w) + b - y), X) + (lambda_ / len(X)) * w\n",
    "        dj_db = (1 / len(X)) * np.sum(np.dot(X, w) + b - y)\n",
    "        w -= alpha * dj_dw\n",
    "        b -= alpha * dj_db\n",
    "    return w, b\n",
    "\n",
    "# Train separate models for each Warengruppe\n",
    "models = {}\n",
    "for i in range(1, 7):\n",
    "    # Filter data for specific Warengruppe\n",
    "    warengruppe_data = wetter_umsatzdaten_kiwo[wetter_umsatzdaten_kiwo[f'Warengruppe_{i}'] == True]\n",
    "    \n",
    "    # Split data\n",
    "    training_data = warengruppe_data[\n",
    "        (warengruppe_data['Datum'] >= training_start_date) & \n",
    "        (warengruppe_data['Datum'] <= training_end_date)\n",
    "    ]\n",
    "    validation_data = warengruppe_data[\n",
    "        (warengruppe_data['Datum'] >= validation_start_date) & \n",
    "        (warengruppe_data['Datum'] <= validation_end_date)\n",
    "    ]\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X_train = training_data[feature_columns].apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float64)\n",
    "    y_train = training_data['Umsatz'].to_numpy()\n",
    "    \n",
    "    X_val = validation_data[feature_columns].apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float64)\n",
    "    y_val = validation_data['Umsatz'].to_numpy()\n",
    "    \n",
    "    # Normalize features\n",
    "    X_mean = np.mean(X_train, axis=0)\n",
    "    X_std = np.std(X_train, axis=0)\n",
    "    X_std[X_std == 0] = 1\n",
    "    X_train = (X_train - X_mean) / X_std\n",
    "    X_val = (X_val - X_mean) / X_std\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    lambda_values = [0.01, 0.1, 1, 10]\n",
    "    best_r_squared = -np.inf\n",
    "    best_lambda = None\n",
    "    \n",
    "    for lambda_ in lambda_values:\n",
    "        w_init = np.zeros(X_train.shape[1])\n",
    "        b_init = 0\n",
    "        w_final, b_final = gradient_descent_reg(X_train, y_train, w_init, b_init, 0.01, 1000, lambda_)\n",
    "        y_val_pred = np.dot(X_val, w_final) + b_final\n",
    "        r_squared = 1 - (np.sum((y_val - y_val_pred) ** 2) / np.sum((y_val - np.mean(y_val)) ** 2))\n",
    "        \n",
    "        if r_squared > best_r_squared:\n",
    "            best_r_squared = r_squared\n",
    "            best_lambda = lambda_\n",
    "    \n",
    "    # Train final model with best lambda\n",
    "    w_final, b_final = gradient_descent_reg(X_train, y_train, np.zeros(X_train.shape[1]), 0, 0.01, 1000, best_lambda)\n",
    "    \n",
    "    # Store model for this Warengruppe\n",
    "    models[i] = {\n",
    "        'w_final': w_final,\n",
    "        'b_final': b_final,\n",
    "        'X_mean': X_mean,\n",
    "        'X_std': X_std,\n",
    "        'best_lambda': best_lambda,\n",
    "        'best_r_squared': best_r_squared,\n",
    "        'feature_columns': feature_columns\n",
    "    }\n",
    "    \n",
    "    # Validate the model for this Warengruppe\n",
    "    y_val_pred = np.dot(X_val, w_final) + b_final\n",
    "    validation_cost = compute_cost_reg(X_val, y_val, w_final, b_final, best_lambda)\n",
    "    mse = np.mean((y_val - y_val_pred) ** 2)\n",
    "    \n",
    "    print(f\"\\nWarengruppe {i} Model:\")\n",
    "    print(f\"Best Lambda: {best_lambda}, Best R^2: {best_r_squared:.4f}\")\n",
    "    print(f\"Validation cost: {validation_cost:.4e}\")\n",
    "    print(f\"Mean Squared Error (MSE) on validation set: {mse:.4e}\")\n",
    "    \n",
    "    # Output model parameters for each Warengruppe\n",
    "    print(\"\\nModel Parameters:\")\n",
    "    for j, feature in enumerate(feature_columns):\n",
    "        print(f\"Feature: {feature}, Coefficient: {w_final[j]:.4f}\")\n",
    "    print(f\"Intercept (b): {b_final:.4f}\")\n",
    "\n",
    "# Optional: Prediction function\n",
    "def predict_sales(features, warengruppe):\n",
    "    model = models[warengruppe]\n",
    "    # Normalize input features\n",
    "    features_normalized = (features - model['X_mean']) / model['X_std']\n",
    "    return np.dot(features_normalized, model['w_final']) + model['b_final']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
