{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lambda: 10, Best R^2: 0.8277\n",
      "Validation cost: 4.7984e+03\n",
      "Mean Squared Error (MSE) on validation set: 5.0827e+03\n",
      "\n",
      "Final Model Parameters:\n",
      "Feature: Is_Weekend, Coefficient: 28.3360\n",
      "Feature: Temperature_Category, Coefficient: -9.3096\n",
      "Feature: Windgeschwindigkeit, Coefficient: 0.9650\n",
      "Feature: Warengruppe_1, Coefficient: -49.4673\n",
      "Feature: Warengruppe_2, Coefficient: 110.0394\n",
      "Feature: Warengruppe_3, Coefficient: -14.9869\n",
      "Feature: Warengruppe_4, Coefficient: -65.5593\n",
      "Feature: Warengruppe_5, Coefficient: 18.5740\n",
      "Intercept (b): 260.1168\n"
     ]
    }
   ],
   "source": [
    "# LinRegModel.ipynb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the processed data and feature columns\n",
    "wetter_umsatzdaten_kiwo = pd.read_csv(\"../1_DatasetCharacteristics/processed_data.csv\")\n",
    "\n",
    "with open(\"../1_DatasetCharacteristics/feature_columns.txt\", \"r\") as f:\n",
    "    feature_columns = f.read().splitlines()\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "training_start_date = '2013-07-01'\n",
    "training_end_date = '2017-07-31'\n",
    "validation_start_date = '2017-08-01'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "training_data = wetter_umsatzdaten_kiwo[\n",
    "    (wetter_umsatzdaten_kiwo['Datum'] >= training_start_date) & \n",
    "    (wetter_umsatzdaten_kiwo['Datum'] <= training_end_date)\n",
    "]\n",
    "validation_data = wetter_umsatzdaten_kiwo[\n",
    "    (wetter_umsatzdaten_kiwo['Datum'] >= validation_start_date) & \n",
    "    (wetter_umsatzdaten_kiwo['Datum'] <= validation_end_date)\n",
    "]\n",
    "\n",
    "X_train = training_data[feature_columns].apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float64)\n",
    "y_train = training_data['Umsatz'].to_numpy()\n",
    "\n",
    "X_val = validation_data[feature_columns].apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float64)\n",
    "y_val = validation_data['Umsatz'].to_numpy()\n",
    "\n",
    "# Normalize features\n",
    "X_mean = np.mean(X_train, axis=0)\n",
    "X_std = np.std(X_train, axis=0)\n",
    "X_std[X_std == 0] = 1  # Avoid division by zero\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_val = (X_val - X_mean) / X_std\n",
    "\n",
    "# Train a regularized linear regression model\n",
    "def compute_cost_reg(X, y, w, b, lambda_):\n",
    "    m = X.shape[0]\n",
    "    cost = (1 / (2 * m)) * np.sum((np.dot(X, w) + b - y) ** 2)\n",
    "    reg_cost = (lambda_ / (2 * m)) * np.sum(w ** 2)\n",
    "    return cost + reg_cost\n",
    "\n",
    "def gradient_descent_reg(X, y, w_in, b_in, alpha, num_iters, lambda_):\n",
    "    w = w_in\n",
    "    b = b_in\n",
    "    for _ in range(num_iters):\n",
    "        dj_dw = (1 / len(X)) * np.dot((np.dot(X, w) + b - y), X) + (lambda_ / len(X)) * w\n",
    "        dj_db = (1 / len(X)) * np.sum(np.dot(X, w) + b - y)\n",
    "        w -= alpha * dj_dw\n",
    "        b -= alpha * dj_db\n",
    "    return w, b\n",
    "\n",
    "# Hyperparameter tuning\n",
    "lambda_values = [0.01, 0.1, 1, 10]\n",
    "best_r_squared = -np.inf\n",
    "best_lambda = None\n",
    "\n",
    "for lambda_ in lambda_values:\n",
    "    w_init = np.zeros(X_train.shape[1])\n",
    "    b_init = 0\n",
    "    w_final, b_final = gradient_descent_reg(X_train, y_train, w_init, b_init, 0.01, 1000, lambda_)\n",
    "    y_val_pred = np.dot(X_val, w_final) + b_final\n",
    "    r_squared = 1 - (np.sum((y_val - y_val_pred) ** 2) / np.sum((y_val - np.mean(y_val)) ** 2))\n",
    "\n",
    "    if r_squared > best_r_squared:\n",
    "        best_r_squared = r_squared\n",
    "        best_lambda = lambda_\n",
    "\n",
    "print(f\"Best Lambda: {best_lambda}, Best R^2: {best_r_squared:.4f}\")\n",
    "\n",
    "# Final model training with best lambda\n",
    "w_final, b_final = gradient_descent_reg(X_train, y_train, np.zeros(X_train.shape[1]), 0, 0.01, 1000, best_lambda)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred = np.dot(X_val, w_final) + b_final\n",
    "validation_cost = compute_cost_reg(X_val, y_val, w_final, b_final, best_lambda)\n",
    "mse = np.mean((y_val - y_val_pred) ** 2)\n",
    "print(f\"Validation cost: {validation_cost:.4e}\")\n",
    "print(f\"Mean Squared Error (MSE) on validation set: {mse:.4e}\")\n",
    "\n",
    "# Output final model parameters\n",
    "print(\"\\nFinal Model Parameters:\")\n",
    "for i, feature in enumerate(feature_columns):\n",
    "    print(f\"Feature: {feature}, Coefficient: {w_final[i]:.4f}\")\n",
    "print(f\"Intercept (b): {b_final:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
