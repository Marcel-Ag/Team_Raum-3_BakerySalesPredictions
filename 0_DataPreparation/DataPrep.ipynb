{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import data from Repo and Merge to one Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install holidays\n",
    "import pandas as pd\n",
    "import holidays\n",
    "\n",
    "# Define the URLs for the additional datasets\n",
    "kiwo_url = 'https://raw.githubusercontent.com/opencampus-sh/einfuehrung-in-data-science-und-ml/main/kiwo.csv'\n",
    "wetter_url = 'https://raw.githubusercontent.com/opencampus-sh/einfuehrung-in-data-science-und-ml/main/wetter.csv'\n",
    "umsatzdaten_gekuerzt_url = 'https://raw.githubusercontent.com/opencampus-sh/einfuehrung-in-data-science-und-ml/main/umsatzdaten_gekuerzt.csv'\n",
    "ferien= '/workspaces/Team_Raum-3_BakerySalesPredictions/0_DataPreparation/ferien_schleswig_holstein_2012_2020.csv'\n",
    "\n",
    "# Load the datasets   \n",
    "kiwo = pd.read_csv(kiwo_url, delimiter=',')\n",
    "wetter = pd.read_csv(wetter_url, delimiter=',')\n",
    "umsatzdaten_gekuerzt = pd.read_csv(umsatzdaten_gekuerzt_url, delimiter=',')\n",
    "ferien_df = pd.read_csv(ferien, delimiter=',')\n",
    "# Merge datasets with a left join to retain all rows from wetter\n",
    "wetter_umsatzdaten = pd.merge(wetter, umsatzdaten_gekuerzt, on=\"Datum\", how=\"left\")\n",
    "\n",
    "# Add KiWo flag   \n",
    "wetter_umsatzdaten['KiWo'] = wetter_umsatzdaten['Datum'].isin(kiwo['Datum']).astype(int)\n",
    "\n",
    "\n",
    "# Read the ferien_schleswig_holstein_2012_2020.csv file\n",
    "ferien_df = pd.read_csv('ferien_schleswig_holstein_2012_2020.csv')\n",
    "\n",
    "# Convert Startdatum and Enddatum to datetime\n",
    "ferien_df['Startdatum'] = pd.to_datetime(ferien_df['Startdatum'], format='%d.%m.%Y')\n",
    "ferien_df['Enddatum'] = pd.to_datetime(ferien_df['Enddatum'], format='%d.%m.%Y')\n",
    "\n",
    "# Create a new column in the existing DataFrame for Ferien\n",
    "wetter_umsatzdaten['Ferien'] = None\n",
    "\n",
    "# Convert the date column in the existing DataFrame to datetime if not already\n",
    "wetter_umsatzdaten['Datum'] = pd.to_datetime(wetter_umsatzdaten['Datum'])\n",
    "\n",
    "# Iterate through the ferien_df and update the Ferien column in existing_df\n",
    "for index, row in ferien_df.iterrows():\n",
    "    mask = (wetter_umsatzdaten['Datum'] >= row['Startdatum']) & (wetter_umsatzdaten['Datum'] <= row['Enddatum'])\n",
    "    wetter_umsatzdaten.loc[mask, 'Ferien'] = row['Ferienart']\n",
    "    \n",
    "# Add a new column 'Is_Ferien' to the wetter_umsatzdaten dataframe\n",
    "wetter_umsatzdaten['Is_Ferien'] = wetter_umsatzdaten['Ferien'].apply(lambda x: 1 if pd.notna(x) else 0)\n",
    "\n",
    "print(wetter_umsatzdaten.head())\n",
    "# Merge the datasets\n",
    "#wetter_umsatzdaten_kiwo = pd.merge(wetter_umsatzdate, wetter_umsatzdaten, on=\"Datum\", how=\"left\")\n",
    "# Convert the 'Datum' column to datetime\n",
    "wetter_umsatzdaten['Datum'] = pd.to_datetime(wetter_umsatzdaten['Datum'])\n",
    "\n",
    "# Define the range of years\n",
    "years = range(2012, 2019 + 1)\n",
    "\n",
    "# Create a list to store the holidays\n",
    "holidays_sh = []\n",
    "\n",
    "# Loop through each year and get the holidays for Schleswig-Holstein\n",
    "for year in years:\n",
    "    for date, name in holidays.Germany(years=year, state='SH').items():\n",
    "        holidays_sh.append((date, name))\n",
    "\n",
    "# Create a set of holiday dates\n",
    "holiday_dates = set(date for date, name in holidays_sh)\n",
    "\n",
    "# Add a new column 'Holiday' to the wetter_umsatzdaten dataframe\n",
    "wetter_umsatzdaten['Holiday'] = wetter_umsatzdaten['Datum'].apply(lambda x: 1 if pd.to_datetime(x).date() in holiday_dates else 0)\n",
    "\n",
    "\n",
    "# Replace NaN in Umsatz with 0\n",
    "wetter_umsatzdaten['Umsatz'] = wetter_umsatzdaten['Umsatz'].fillna(0)\n",
    "\n",
    "# Replace NaN in Warengruppe with 0\n",
    "wetter_umsatzdaten['Warengruppe'] = wetter_umsatzdaten['Warengruppe'].fillna(0).astype(int)\n",
    "\n",
    "# Identify rows where Warengruppe is 0\n",
    "rows_with_zero_warengruppe = wetter_umsatzdaten[wetter_umsatzdaten['Warengruppe'] == 0]\n",
    "\n",
    "# Create an empty list to store the expanded rows\n",
    "expanded_rows = []\n",
    "\n",
    "# For each row with Warengruppe = 0, create 6 copies with Warengruppe values from 1 to 6\n",
    "for _, row in rows_with_zero_warengruppe.iterrows():\n",
    "    for warengruppe_value in range(1, 7):  # For Warengruppe 1 to 5\n",
    "        new_row = row.copy()  # Copy the original row\n",
    "        new_row['Warengruppe'] = warengruppe_value  # Update the Warengruppe\n",
    "        expanded_rows.append(new_row)  # Add the new row to the list\n",
    "\n",
    "# Convert the list of expanded rows to a DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Remove the original rows with Warengruppe = 0 from the dataframe\n",
    "wetter_umsatzdaten = wetter_umsatzdaten[wetter_umsatzdaten['Warengruppe'] != 0]\n",
    "\n",
    "# Concatenate the original dataframe (with the Warengruppe = 0 rows removed) and the expanded rows\n",
    "wetter_umsatzdaten = pd.concat([wetter_umsatzdaten, expanded_df], ignore_index=True)\n",
    "\n",
    "# Sort the dataframe by 'Datum' and 'Warengruppe'\n",
    "wetter_umsatzdaten = wetter_umsatzdaten.sort_values(by=['Datum', 'Warengruppe']).reset_index(drop=True)\n",
    "\n",
    "# Create a new column 'ID' to match the sample submission format (YYMMDDW)\n",
    "wetter_umsatzdaten['id'] = (\n",
    "    wetter_umsatzdaten['Datum'].dt.strftime('%y%m%d').astype(str) + \n",
    "    wetter_umsatzdaten['Warengruppe'].astype(str)\n",
    ").astype(int)\n",
    "\n",
    "# Print the first few rows to verify the new ID format\n",
    "print(wetter_umsatzdaten[['Datum', 'Warengruppe', 'id']].head())\n",
    "\n",
    "# Save merged dataset directly\n",
    "wetter_umsatzdaten.to_csv(\"wetter_umsatzdaten_kiwo_hol_id.csv\", index=False)\n",
    "\n",
    "print(\"Merge complete. Data saved for subsequent processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "wetter_umsatzdaten_kiwo = pd.read_csv(\"../0_DataPreparation/wetter_umsatzdaten_kiwo_hol_id.csv\")\n",
    "\n",
    "print(\"Data Overview:\")\n",
    "print(wetter_umsatzdaten_kiwo.info())\n",
    "print(\"Shape of Data:\", wetter_umsatzdaten_kiwo.shape)\n",
    "print(\"Missing values per column:\")\n",
    "print(wetter_umsatzdaten_kiwo.isnull().sum())\n",
    "#print(wetter_umsatzdaten.head())\n",
    "#print(wetter_umsatzdaten.tail())\n",
    "\n",
    "#Load the data\n",
    "df = wetter_umsatzdaten_kiwo.copy()\n",
    "print(df.info())\n",
    "\n",
    "#barplot of complete data\n",
    "msno.bar(df, figsize=(12, 6))\n",
    "plt.title('Data Completeness Bar Plot')\n",
    "plt.show()\n",
    "\n",
    "#Visualize missing data for 'Bewoelkung'\n",
    "msno.matrix(df, figsize=(12, 6))\n",
    "plt.title('Missing Data Matrix Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create reference data frame with listwise deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load original data\n",
    "df_for_listwise = pd.read_csv(\"../0_DataPreparation/wetter_umsatzdaten_kiwo_hol_id.csv\")\n",
    "#listwise deletion of rows with missing Bewoelkung values and missing Wettercodes values\n",
    "df_listwise = df_for_listwise.dropna(subset=['Bewoelkung', 'Wettercode'])\n",
    "print(\"Shape of Data after listwise deletion:\", df_listwise.shape)\n",
    "#visualize bar completeness plot of deleted matrix  \n",
    "msno.bar(df_listwise, figsize=(12, 6))\n",
    "plt.title('Data Completeness Bar Plot after Listwise Deletion')\n",
    "plt.show()\n",
    "#visualize matrix plot of deleted matrix\n",
    "msno.matrix(df_listwise, figsize=(12, 6))\n",
    "#save the data\n",
    "df_listwise.to_csv(\"../0_DataPreparation/wetter_umsatzdaten_kiwo_hol_id_listwise.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation of Bewoelkung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "import missingno as msno\n",
    "\n",
    "\n",
    "# Ensure that 'Datum' is in datetime format\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "\n",
    "# Create a mask for the original missing values (before imputation)\n",
    "missing_mask_bewoelkung = df['Bewoelkung'].isnull()\n",
    "\n",
    "# Extract dates with missing 'Bewoelkung' values\n",
    "missing_bewoelkung_dates = df[df['Bewoelkung'].isnull()]['Datum']\n",
    "print(missing_bewoelkung_dates)\n",
    "\n",
    "# Convert to datetime, though it should already be in the correct format\n",
    "missing_bewoelkung_dates = pd.to_datetime(missing_bewoelkung_dates)\n",
    "\n",
    "# Extract the unique missing dates\n",
    "unique_missing_dates = missing_bewoelkung_dates.unique()\n",
    "\n",
    "# Create a figure and axis for plotting the 'Bewoelkung' values before imputation\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Loop through each missing date\n",
    "for missing_date in unique_missing_dates:\n",
    "    missing_date = pd.to_datetime(missing_date)\n",
    "    start_date = missing_date - pd.Timedelta(days=10)\n",
    "    end_date = missing_date + pd.Timedelta(days=10)\n",
    "    \n",
    "    date_range_df = df[(df['Datum'] >= start_date) & (df['Datum'] <= end_date)]\n",
    "    \n",
    "    ax.plot(date_range_df['Datum'], date_range_df['Bewoelkung'], marker='o', label=f'Missing Date: {missing_date.date()}')\n",
    "\n",
    "ax.set_title('Bewoelkung 10 Days Before and 10 Days After Missing Dates')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Bewoelkung')\n",
    "plt.xticks(rotation=45)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Select the columns to be used for KNN imputation\n",
    "columns_for_imputation = ['Bewoelkung', 'Temperatur', 'Windgeschwindigkeit']\n",
    "\n",
    "# Create a copy of the dataframe with only the relevant columns\n",
    "df_impute = df[columns_for_imputation].copy()\n",
    "\n",
    "# Initialize the KNNImputer with the desired number of neighbors\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Perform the imputation\n",
    "df_imputed = knn_imputer.fit_transform(df_impute)\n",
    "\n",
    "# Update the original dataframe with the imputed values for 'Bewoelkung'\n",
    "# Round the imputed values to integers\n",
    "df['Bewoelkung'] = df_imputed[:, 0].round().astype(int)\n",
    "\n",
    "# Create a mask for imputed values based on original missing values\n",
    "df['Bewoelkung_Imputed'] = missing_mask_bewoelkung.astype(int)\n",
    "\n",
    "# Verify the imputation and new column for imputed values\n",
    "print(df[['Datum', 'Bewoelkung', 'Bewoelkung_Imputed']].head(10))\n",
    "\n",
    "# Compare original vs imputed data for 'Bewoelkung'\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for missing_date in unique_missing_dates:\n",
    "    start_date = missing_date - pd.Timedelta(days=10)\n",
    "    end_date = missing_date + pd.Timedelta(days=10)\n",
    "    \n",
    "    date_range_df = df[(df['Datum'] >= start_date) & (df['Datum'] <= end_date)]\n",
    "    \n",
    "    ax.plot(date_range_df['Datum'], date_range_df['Bewoelkung'], marker='o', linestyle='--', label=f'Original Missing Date: {missing_date.date()}')\n",
    "    ax.plot(date_range_df['Datum'], date_range_df['Bewoelkung'], marker='x', linestyle='-', label=f'Imputed Missing Date: {missing_date.date()}')\n",
    "\n",
    "ax.set_title('Bewoelkung 10 Days Before and 10 Days After Missing Dates (Original vs Imputed)')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Bewoelkung')\n",
    "plt.xticks(rotation=45)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Bar plot for completeness of the data\n",
    "msno.bar(df, figsize=(12, 6))\n",
    "plt.title('Data Completeness Bar Plot')\n",
    "plt.show()\n",
    "\n",
    "# Save the data with imputed values\n",
    "df.to_csv(\"wetter_umsatzdaten_kiwo_hol_id_bewoelkung_imputed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation for Wettercode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv(\"wetter_umsatzdaten_kiwo_hol_id_bewoelkung_imputed.csv\")\n",
    "\n",
    "# Create a mask for the original missing values for 'Wettercode' before imputation\n",
    "missing_mask_wettercode = df['Wettercode'].isnull()\n",
    "\n",
    "# Ensure that 'Wettercode' column is numeric if it's categorical\n",
    "# We can use 'astype' to convert categorical values to numerical form.\n",
    "# But instead of factorizing, directly treat the column as it is.\n",
    "df['Wettercode'] = pd.to_numeric(df['Wettercode'], errors='coerce')\n",
    "\n",
    "# Select the columns for KNN imputation\n",
    "columns_for_imputation = ['Bewoelkung', 'Temperatur', 'Windgeschwindigkeit', 'Wettercode']\n",
    "\n",
    "# Create a copy of the dataframe with only the relevant columns for imputation\n",
    "df_impute = df[columns_for_imputation].copy()\n",
    "\n",
    "# Initialize the KNNImputer with the desired number of neighbors\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Perform the imputation\n",
    "df_imputed = knn_imputer.fit_transform(df_impute)\n",
    "\n",
    "# Round the imputed values of 'Wettercode' to the nearest integer\n",
    "df['Wettercode'] = np.round(df_imputed[:, 3]).astype(int)\n",
    "\n",
    "# Create a new mask that tracks imputed values for 'Wettercode'\n",
    "# If the value was originally missing, and it's now imputed, this will mark it as '1'\n",
    "df['Wettercode_Imputed'] = missing_mask_wettercode.astype(int)\n",
    "\n",
    "# Verify the imputation and the new column marking imputed values\n",
    "print(df[['Datum', 'Wettercode', 'Wettercode_Imputed']].head(10))\n",
    "\n",
    "# Statistics of the imputed 'Wettercode' column\n",
    "imputed_stats_wettercode = pd.Series(df_imputed[:, 3]).describe()\n",
    "print(\"Statistics of the imputed column (Wettercode):\")\n",
    "print(imputed_stats_wettercode)\n",
    "\n",
    "# Statistics of the un-imputed 'Wettercode' column\n",
    "unimputed_stats_wettercode = df['Wettercode'].describe()\n",
    "print(\"Statistics of the un-imputed column (Wettercode):\")\n",
    "print(unimputed_stats_wettercode)\n",
    "\n",
    "# Bar plot of data completeness\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "msno.bar(df, figsize=(12, 6))\n",
    "plt.title('Data Completeness Bar Plot')\n",
    "plt.show()\n",
    "\n",
    "# Save the data with imputed values\n",
    "df.to_csv(\"wetter_umsatzdaten_kiwo_hol_id_bewoelkung_wettercode_imputed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 2: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load listwise deleted data\n",
    "#wetter_umsatzdaten_kiwo = pd.read_csv(\"../0_DataPreparation/wetter_umsatzdaten_kiwo_hol_id_listwise.csv\")\n",
    "\n",
    "# Load the imputed data\n",
    "wetter_umsatzdaten_kiwo = pd.read_csv(\"wetter_umsatzdaten_kiwo_hol_id_bewoelkung_wettercode_imputed.csv\")\n",
    "\n",
    "# Step 1: Inspect the data\n",
    "print(\"Data Overview:\")\n",
    "print(wetter_umsatzdaten_kiwo.tail())\n",
    "print(\"Shape of Data:\", wetter_umsatzdaten_kiwo.shape)\n",
    "print(\"Missing values per column:\")\n",
    "print(wetter_umsatzdaten_kiwo.isnull().sum())\n",
    "\n",
    "\n",
    "# Convert 'Datum' to datetime and add a weekday column\n",
    "wetter_umsatzdaten_kiwo['Datum'] = pd.to_datetime(wetter_umsatzdaten_kiwo['Datum'], errors='coerce')\n",
    "wetter_umsatzdaten_kiwo['Wochentag'] = wetter_umsatzdaten_kiwo['Datum'].dt.day_name()\n",
    "wetter_umsatzdaten_kiwo['Is_Weekend'] = wetter_umsatzdaten_kiwo['Datum'].dt.weekday.isin([5, 6]).astype(int)\n",
    "\n",
    "# Add holiday category\n",
    "def classify_main_ferien(ferien):\n",
    "    if ferien == 'Sommerferien':\n",
    "        return 1   # Sommerferien\n",
    "    elif ferien == 'Weihnachtsferien':\n",
    "        return 2    # Weihnachtsferien\n",
    "    else:\n",
    "        return 0   # no sommer or winterholidays\n",
    "\n",
    "wetter_umsatzdaten_kiwo['Weihnachten_Sommer'] = wetter_umsatzdaten_kiwo['Ferien'].apply(classify_main_ferien)\n",
    "\n",
    "# Add christmas sales flag\n",
    "def christmas_sales_flag(date):\n",
    "    if date.month == 12 and 1 <= date.day <= 24:\n",
    "        return 1 # christmas sales\n",
    "    else:\n",
    "        return 0 # no christmas sales\n",
    "\n",
    "wetter_umsatzdaten_kiwo['Christmas_Sales'] = wetter_umsatzdaten_kiwo['Datum'].apply(christmas_sales_flag)\n",
    "\n",
    "# Add Sommerferien flag\n",
    "def sommerferien_flag(ferien):\n",
    "    if ferien == 'Sommerferien':\n",
    "        return 1 #Sommerferien\n",
    "    else:\n",
    "        return 0 # no Sommerferien\n",
    "\n",
    "wetter_umsatzdaten_kiwo['Sommerferien_Flag'] = wetter_umsatzdaten_kiwo['Datum'].apply(sommerferien_flag)\n",
    "\n",
    "\n",
    "# Add a ferien tag\n",
    "def classify_ferien(ferien):\n",
    "    if ferien == 'Osterferien':\n",
    "        return 1  # Osterferien\n",
    "    elif ferien == 'Pfingstferien':\t\n",
    "        return 2  # Pfingstferien\n",
    "    elif ferien == 'Sommerferien':\n",
    "        return 3   # Sommerferien\n",
    "    elif ferien == 'Herbstferien':\n",
    "        return 4    # Herbstferien\n",
    "    elif ferien == 'Weihnachtsferien':\n",
    "        return 5    # Weihnachtsferien\n",
    "    else:\n",
    "        return 0   # no holidays\n",
    "\n",
    "wetter_umsatzdaten_kiwo['Ferien_Category'] = wetter_umsatzdaten_kiwo['Ferien'].apply(classify_ferien)\n",
    "\n",
    "\n",
    "\n",
    "# Add a temperature category\n",
    "def classify_temperature(temp):\n",
    "    if temp < 0:\n",
    "        return -2  # Very Cold\n",
    "    elif 0 <= temp <= 10:\n",
    "        return -1  # Cold\n",
    "    elif 10 < temp <= 20:\n",
    "        return 1   # Warm\n",
    "    else:\n",
    "        return 2   # Very Warm\n",
    "\n",
    "wetter_umsatzdaten_kiwo['Temperature_Category'] = wetter_umsatzdaten_kiwo['Temperatur'].apply(classify_temperature)\n",
    "\n",
    "\n",
    "# Add a Beaufort scale categorization function\n",
    "def classify_wind_speed_beaufort(wind_speed):\n",
    "    if wind_speed <= 0.2:\n",
    "        return 0  # Calm\n",
    "    elif wind_speed <= 1.5:\n",
    "        return 1  # Light Air\n",
    "    elif wind_speed <= 3.3:\n",
    "        return 2  # Light Breeze\n",
    "    elif wind_speed <= 5.4:\n",
    "        return 3  # Gentle Breeze\n",
    "    elif wind_speed <= 7.9:\n",
    "        return 4  # Moderate Breeze\n",
    "    elif wind_speed <= 10.7:\n",
    "        return 5  # Fresh Breeze\n",
    "    elif wind_speed <= 13.8:\n",
    "        return 6  # Strong Breeze\n",
    "    elif wind_speed <= 17.1:\n",
    "        return 7  # Near Gale\n",
    "    elif wind_speed <= 20.7:\n",
    "        return 8  # Gale\n",
    "    elif wind_speed <= 24.4:\n",
    "        return 9  # Strong Gale\n",
    "    elif wind_speed <= 28.4:\n",
    "        return 10  # Storm\n",
    "    elif wind_speed <= 32.6:\n",
    "        return 11  # Violent Storm\n",
    "    else:\n",
    "        return 12  # Hurricane\n",
    "\n",
    "wetter_umsatzdaten_kiwo['Windgeschwindigkeit_Beaufort'] = wetter_umsatzdaten_kiwo['Windgeschwindigkeit'].apply(classify_wind_speed_beaufort)\n",
    "\n",
    "#add a wind status\n",
    "def classify_wind_status(wind_speed_beaufort):\n",
    "    if wind_speed_beaufort <= 2:\n",
    "        return 0  # Calm\n",
    "    elif wind_speed_beaufort <= 4:\n",
    "        return 1  # Light Air\n",
    "    elif wind_speed_beaufort <= 6:\n",
    "        return 2  # Light Breeze\n",
    "    elif wind_speed_beaufort <= 8:\n",
    "        return 3  # Gentle Breeze\n",
    "    elif wind_speed_beaufort <= 10:\n",
    "        return 4  # Moderate Breeze\n",
    "    elif wind_speed_beaufort <= 12:\n",
    "        return 5  # Fresh Breeze\n",
    "    else:\n",
    "        return 6  # Strong Breeze\n",
    "\n",
    "wetter_umsatzdaten_kiwo['Wind_Status'] = wetter_umsatzdaten_kiwo['Windgeschwindigkeit_Beaufort'].apply(classify_wind_status)\n",
    "\n",
    "# Add a column for Rain_Status based on Wettercode\n",
    "def map_rain_status(wettercode):\n",
    "    rain_status_mapping = {\n",
    "        0: 0,\n",
    "        20: 0,\n",
    "        21: 0,\n",
    "        61: 1,\n",
    "        63: 1,\n",
    "        65: 1,\n",
    "        95: 2\n",
    "    }\n",
    "    return rain_status_mapping.get(wettercode, -1)  # Default to -1 for unknown codes\n",
    "\n",
    "wetter_umsatzdaten_kiwo['Rain_Status'] = wetter_umsatzdaten_kiwo['Wettercode'].apply(map_rain_status)\n",
    "\n",
    "#Add acolumn for Cloud_Status based on BewÃ¶lkung\n",
    "def map_cloud_status(bewoelkung):\n",
    "    if bewoelkung < 1:\n",
    "        return 0  # sunny\n",
    "    elif bewoelkung <= 3:\n",
    "        return 1 # clear\n",
    "    elif bewoelkung <= 6:\n",
    "        return 2  # Partly Cloudy\n",
    "    elif bewoelkung <= 7:\n",
    "        return 3  # Cloudy\n",
    "    else:\n",
    "        return 4  # totally Cloudy\n",
    "\n",
    "wetter_umsatzdaten_kiwo['Cloud_Status'] = wetter_umsatzdaten_kiwo['Bewoelkung'].apply(map_cloud_status)\n",
    "\n",
    "\n",
    "# Perform one-hot encoding for 'Warengruppe'\n",
    "warengruppe_encoded = pd.get_dummies(wetter_umsatzdaten_kiwo['Warengruppe'], prefix='Warengruppe')\n",
    "\n",
    "# Convert the True/False values to 1/0\n",
    "warengruppe_encoded = warengruppe_encoded.astype(int)\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original dataframe\n",
    "wetter_umsatzdaten_kiwo = pd.concat([wetter_umsatzdaten_kiwo, warengruppe_encoded], axis=1)\n",
    "\n",
    "\n",
    "# Dynamically create a list of feature columns\n",
    "feature_columns = [\n",
    "    'KiWo', \n",
    "    'Is_Weekend', \n",
    "    'Temperature_Category', \n",
    "    'Wind_Status', \n",
    "    'Rain_Status',\n",
    "    'Cloud_Status',\n",
    "    'Is_Ferien',\n",
    "    #'Weihnachten_Sommer'\n",
    "    'Holiday'\n",
    "] + list(warengruppe_encoded.columns)\n",
    "\n",
    "# Step 3: Save listwise Processed Data\n",
    "#wetter_umsatzdaten_kiwo.to_csv(\"processed_data_deleted.csv\", index=False)\n",
    "\n",
    "#save imputed processed data\n",
    "wetter_umsatzdaten_kiwo.to_csv(\"processed_data_imputed.csv\", index=False)\n",
    "\n",
    "# Save feature columns to a file for use in the modeling stage\n",
    "with open(\"feature_columns.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(feature_columns))\n",
    "\n",
    "print(\"Data preparation and characterization complete. Processed data and feature columns saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
